{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1035248d",
   "metadata": {},
   "source": [
    "# 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bd9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수 : 72\n",
      "토큰수 : 15\n",
      "[220, 543, 5850, 7342, 6129, 1088, 262, 2119, 24433, 339, 991, 550, 465, 1336, 82]\n",
      "  which Harry watched fly around the room wishing he still had his fulls\n",
      "220 :  \n",
      "543 :  which\n",
      "5850 :  Harry\n",
      "7342 :  watched\n",
      "6129 :  fly\n",
      "1088 :  around\n",
      "262 :  the\n",
      "2119 :  room\n",
      "24433 :  wishing\n",
      "339 :  he\n",
      "991 :  still\n",
      "550 :  had\n",
      "465 :  his\n",
      "1336 :  full\n",
      "82 : s\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"  which Harry watched fly around the room wishing he still had his fulls\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수 :\", len(text))  # 글자수: 26\n",
    "print(\"토큰수 :\", len(tokens))  # 토큰수: 6\n",
    "print(tokens)  # [15496, 2159, 257, 281, 3453, 13]\n",
    "print(tokenizer.decode(tokens))  # Harry Potter was a wizard.\n",
    "for token in tokens:\n",
    "    print(token, \":\", tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e8c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\github\\llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n",
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. GPT-2 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 2. GPT-2는 기본 pad_token이 없어서 직접 설정\n",
    "# if tokenizer.pad_token is None:\n",
    "#     special_tokens_dict = {'pad_token': '<|pad|>'}\n",
    "#     num_added = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# pad를 따로 추가하지 말고, eos를 그대로 pad로 사용\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pad_id = tokenizer.pad_token_id  # == eos_id\n",
    "\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d61185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 100000\n",
      "원본 샘플:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나 넣어놨으니까 \"\\n\\n\" 기준으로 자름\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"샘플 개수:\", len(train_samples))\n",
    "\n",
    "example = train_samples[0]\n",
    "print(\"원본 샘플:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e9b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 512])\n",
      "attention_mask shape: torch.Size([1, 512])\n",
      "디코딩된 텍스트:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "max_len = 512  # 임시\n",
    "\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=max_len,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",  # PyTorch 텐서로\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"]        # shape: (1, max_len)\n",
    "attention_mask = enc[\"attention_mask\"]  # shape: (1, max_len)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# 디코딩해서 잘 복원되는지 확인\n",
    "decoded = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "print(\"디코딩된 텍스트:\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1432b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class LottoDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len: int, focus_len: int = 118):\n",
    "        \"\"\"\n",
    "        focus_len: 시퀀스 뒤에서부터 몇 개 토큰을\n",
    "                   '결과/수익률 구간'이라고 보고 가중치를 줄지\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.eos = tokenizer.eos_token\n",
    "        self.focus_len = focus_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_txt = self.texts[idx]\n",
    "\n",
    "        txt = row_txt + self.eos\n",
    "\n",
    "        # max_len+1 길이로 토큰화 → x:[:-1], y:[1:] 사용\n",
    "        enc = self.tokenizer(\n",
    "            txt,\n",
    "            max_length=self.max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn_mask = enc[\"attention_mask\"][0]  # (max_len+1,)\n",
    "\n",
    "        # 언어모델용 input/target\n",
    "        x = ids[:-1].clone()       # (max_len,)\n",
    "        y = ids[1:].clone()        # (max_len,)\n",
    "        x_mask = attn_mask[:-1].clone()\n",
    "\n",
    "        # pad 위치는 loss에서 무시되도록 -100\n",
    "        y[x_mask == 0] = -100\n",
    "\n",
    "        # ----- roi_mask 생성 (결과/수익률 구간) -----\n",
    "        # 실제 토큰 길이 (pad 제외)\n",
    "        valid_len = int(x_mask.sum().item())   # 예: 380 토큰\n",
    "        roi_mask = torch.zeros_like(x_mask)    # (max_len,)\n",
    "\n",
    "        # 뒤에서 focus_len개를 결과 구간으로 설정\n",
    "        start = max(0, valid_len - self.focus_len)\n",
    "        roi_mask[start:valid_len] = 1\n",
    "\n",
    "        return x, y, x_mask, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e2f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([512])\n",
      "y shape: torch.Size([512])\n",
      "x_mask shape: torch.Size([512])\n",
      "roi_mask shape: torch.Size([512])\n",
      "x[:20]: tensor([26316,    28, 27559,   198, 14463,    28,    16,    11,  1157,    11,\n",
      "         1314,    11,  1507,    11,  1959,    11,  2548,   198,  4189,   385])\n",
      "y[:20]: tensor([   28, 27559,   198, 14463,    28,    16,    11,  1157,    11,  1314,\n",
      "           11,  1507,    11,  1959,    11,  2548,   198,  4189,   385,    28])\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "train_ds = LottoDataset(train_samples, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "x, y, x_mask, roi_mask = train_ds[0]\n",
    "\n",
    "print(\"x shape:\", x.shape)          # torch.Size([256])\n",
    "print(\"y shape:\", y.shape)          # torch.Size([256])\n",
    "print(\"x_mask shape:\", x_mask.shape)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)\n",
    "\n",
    "print(\"x[:20]:\", x[:20])\n",
    "print(\"y[:20]:\", y[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f8c7",
   "metadata": {},
   "source": [
    "DataSet 출력값 예시\n",
    "\n",
    "X TEXT:\n",
    "money=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "\n",
    "Y TEXT:\n",
    "oney=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a468413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|>\n",
      "pad_token_id: 50256\n",
      "vocab_size: 50257\n",
      "\n",
      "input_ids shape: torch.Size([512])\n",
      "attention_mask shape: torch.Size([512])\n",
      "\n",
      "=== DECODED TEXT ===\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "\n",
    "\n",
    "# lotto_train.txt 읽기\n",
    "def load_text_samples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "\n",
    "# 샘플 하나\n",
    "example = train_samples[0]\n",
    "# print(\"=== ORIGINAL TEXT ===\")\n",
    "# print(example)\n",
    "\n",
    "# encode\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"][0]\n",
    "attention_mask = enc[\"attention_mask\"][0]\n",
    "\n",
    "print(\"\\ninput_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# decode\n",
    "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== DECODED TEXT ===\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4947dc",
   "metadata": {},
   "source": [
    "# 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ae71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 샘플 수: 100000\n",
      "첫 샘플 원본:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나씩 있다고 가정 → \"\\n\\n\" 기준 split\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"train 샘플 수:\", len(train_texts))\n",
    "print(\"첫 샘플 원본:\")\n",
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8db334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([4, 512])\n",
      "y_batch shape: torch.Size([4, 512])\n",
      "mask_batch shape: torch.Size([4, 512])\n",
      "roi_mask shape: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 512  # 일단 256 정도로 가정\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 배치 하나만 꺼내서 확인해보자\n",
    "x_batch, y_batch, mask_batch, roi_mask = next(iter(train_loader))\n",
    "\n",
    "print(\"x_batch shape:\", x_batch.shape)        # (B, T) = (4, 256)\n",
    "print(\"y_batch shape:\", y_batch.shape)        # (4, 256)\n",
    "print(\"mask_batch shape:\", mask_batch.shape)  # (4, 256)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)      # (4, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fabdab",
   "metadata": {},
   "source": [
    "### focus_len 마지막 증가할 가중치 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e711222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_focus_len(texts, tokenizer, max_len: int, \n",
    "                       target_tokens=(\"3개일치\", \"수익률\"),\n",
    "                       sample_size: int = 1000,\n",
    "                       quantile: float = 0.95):\n",
    "    \"\"\"\n",
    "    texts: lotto_train.txt에서 읽어온 전체 텍스트 리스트\n",
    "    target_tokens: 결과/수익률 블록을 대표하는 토큰 문자열들\n",
    "    sample_size: 몇 개 샘플만 뽑아서 통계 낼지\n",
    "    quantile: 상위 몇 %까지 커버할지 (0.95면 95퍼센타일)\n",
    "    \"\"\"\n",
    "    n = min(len(texts), sample_size)\n",
    "    lengths = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row_txt = texts[i]\n",
    "        txt = row_txt + tokenizer.eos_token\n",
    "\n",
    "        enc = tokenizer(\n",
    "            txt,\n",
    "            max_length=max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn = enc[\"attention_mask\"][0]     # (max_len+1,)\n",
    "\n",
    "        valid_len = int(attn.sum().item())\n",
    "        ids_list = ids[:valid_len].tolist()\n",
    "\n",
    "        # 이 샘플에서 결과 블록 시작 위치를 찾는다\n",
    "        start_idx = valid_len  # 기본값: 못 찾으면 tail=0\n",
    "\n",
    "        for tok_str in target_tokens:\n",
    "            pat = tokenizer(tok_str, add_special_tokens=False)[\"input_ids\"]\n",
    "            L = len(pat)\n",
    "\n",
    "            for j in range(valid_len - L + 1):\n",
    "                if ids_list[j:j+L] == pat:\n",
    "                    start_idx = min(start_idx, j)\n",
    "                    break  # 이 토큰은 찾았으니 다음 토큰으로\n",
    "\n",
    "        tail_len = valid_len - start_idx\n",
    "        if tail_len < 0:\n",
    "            tail_len = 0\n",
    "\n",
    "        lengths.append(tail_len)\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "    print(\"샘플 개수:\", len(lengths))\n",
    "    print(\"min tail_len:\", lengths.min())\n",
    "    print(\"avg tail_len:\", lengths.mean())\n",
    "    print(\"max tail_len:\", lengths.max())\n",
    "    focus_len = int(np.quantile(lengths, quantile))\n",
    "    print(f\"{int(quantile*100)} 퍼센타일 tail_len:\", focus_len)\n",
    "\n",
    "    return focus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fee5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 1000\n",
      "min tail_len: 117\n",
      "avg tail_len: 117.176\n",
      "max tail_len: 120\n",
      "95 퍼센타일 tail_len: 118\n",
      "최종 선택된 focus_len = 118\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")\n",
    "\n",
    "focus_len = estimate_focus_len(\n",
    "    train_texts,\n",
    "    tokenizer,\n",
    "    max_len=max_len,\n",
    "    target_tokens=(\"3개일치\", \"수익률\"),\n",
    "    sample_size=1000,\n",
    "    quantile=0.95,\n",
    ")\n",
    "print(\"최종 선택된 focus_len =\", focus_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818c09",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43da2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class GPTConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        n_layer: int = 4,\n",
    "        n_head: int = 4,\n",
    "        d_model: int = 256,\n",
    "        d_ff: int = 1024,\n",
    "        max_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.max_len = max_len\n",
    "        self.dropout = dropout\n",
    "        self.pad_id = pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.d_model = config.d_model\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.qkv = nn.Linear(config.d_model, 3 * config.d_model)\n",
    "        self.proj = nn.Linear(config.d_model, config.d_model)\n",
    "\n",
    "        mask = torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\",\n",
    "            mask.view(1, 1, config.max_len, config.max_len)\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        head_dim = C // H\n",
    "\n",
    "        qkv = self.qkv(x)              # (B, T, 3C)\n",
    "        q, k, v = qkv.split(C, dim=2)  # (B, T, C) each\n",
    "\n",
    "        q = q.view(B, T, H, head_dim).transpose(1, 2)  # (B, H, T, head_dim)\n",
    "        k = k.view(B, T, H, head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, H, head_dim).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / (head_dim ** 0.5)  # (B, H, T, T)\n",
    "\n",
    "        causal_mask = self.causal_mask[:, :, :T, :T]\n",
    "        att = att.masked_fill(causal_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: (B, T) → (B, 1, 1, T)\n",
    "            pad_mask = attn_mask.view(B, 1, 1, T)\n",
    "            att = att.masked_fill(pad_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "\n",
    "        y = att @ v                    # (B, H, T, head_dim)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fea54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.d_ff, config.d_model),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = x + self.attn(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fea343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        self.pos_emb = nn.Embedding(config.max_len, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(config.n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        self.head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "\n",
    "        # (선택) 입력 임베딩과 출력 head weight tying\n",
    "        self.head.weight = self.tok_emb.weight\n",
    "\n",
    "    def forward(self, idx, attn_mask=None):\n",
    "        # idx: (B, T)\n",
    "        B, T = idx.size()\n",
    "        device = idx.device\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device)\n",
    "        pos = pos.unsqueeze(0).expand(B, T)  # (B, T)\n",
    "\n",
    "        x = self.tok_emb(idx) + self.pos_emb(pos)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b44d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, tokenizer, prompt: str, max_new_tokens: int = 200, device=\"cpu\"):\n",
    "    \n",
    "    model.eval()\n",
    "    max_len = model.config.max_len\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # 1) 처음에는 패딩 없이 실제 길이만큼만 인코딩\n",
    "    enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    x = enc[\"input_ids\"].to(device)      # (1, T0)\n",
    "    attn_mask = enc[\"attention_mask\"].to(device)  # (1, T0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 2) 모델에 넣기 전에 길이가 max_len을 넘으면 뒤에서 max_len만 유지\n",
    "        if x.size(1) > max_len:\n",
    "            x = x[:, -max_len:]\n",
    "            attn_mask = attn_mask[:, -max_len:]\n",
    "\n",
    "        # 3) forward\n",
    "        logits = model(x, attn_mask=attn_mask)        # (1, T, vocab)\n",
    "        last_logits = logits[:, -1, :]                # (1, vocab)\n",
    "\n",
    "        probs = torch.softmax(last_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "        next_token = next_id.item()\n",
    "\n",
    "        if next_token == eos_token_id:\n",
    "            break\n",
    "\n",
    "        # 4) 새 토큰 이어붙이기\n",
    "        x = torch.cat([x, next_id], dim=1)  # (1, T+1)\n",
    "        next_mask = torch.ones_like(next_id, device=device)\n",
    "        attn_mask = torch.cat([attn_mask, next_mask], dim=1)\n",
    "\n",
    "    # 5) 결과 디코딩\n",
    "    out_ids = x[0].tolist()\n",
    "    text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de740e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "train samples: 100000\n",
      "val samples: 10000\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 2) 데이터 로딩\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")  # 없다면 주석 처리하고 train만 써도 됨\n",
    "\n",
    "print(\"train samples:\", len(train_texts))\n",
    "print(\"val samples:\", len(val_texts))\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "val_ds = LottoDataset(val_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "# 3) 모델 & optimizer & loss\n",
    "config = GPTConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    d_model=256,\n",
    "    d_ff=1024,\n",
    "    max_len=max_len,\n",
    "    dropout=0.1,\n",
    "    pad_id=pad_id,\n",
    ")\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81b8fe",
   "metadata": {},
   "source": [
    "# Eos 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e978db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9653984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n",
      "\n",
      "DATASET 내부 tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL tokenizer:\")\n",
    "print(\"  pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)\n",
    "\n",
    "print(\"\\nDATASET 내부 tokenizer:\")\n",
    "print(\"  pad_token:\", train_ds.tokenizer.pad_token, \"id:\", train_ds.tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", train_ds.tokenizer.eos_token, \"id:\", train_ds.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab8a79",
   "metadata": {},
   "source": [
    "#학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9223e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=1.2546, val_loss=0.7292\n",
      "[Epoch 002] train_loss=0.3013, val_loss=0.6328\n",
      "[Epoch 003] train_loss=0.2679, val_loss=0.6131\n",
      "[Epoch 004] train_loss=0.2590, val_loss=0.6068\n",
      "[Epoch 005] train_loss=0.2555, val_loss=0.6057\n",
      "[Epoch 006] train_loss=0.2537, val_loss=0.6047\n",
      "[Epoch 007] train_loss=0.2524, val_loss=0.6037\n",
      "[Epoch 008] train_loss=0.2517, val_loss=0.6032\n",
      "[Epoch 009] train_loss=0.2513, val_loss=0.6032\n",
      "[Epoch 010] train_loss=0.2510, val_loss=0.6027\n",
      "[Epoch 011] train_loss=0.2507, val_loss=0.6027\n",
      "[Epoch 012] train_loss=0.2506, val_loss=0.6024\n",
      "[Epoch 013] train_loss=0.2504, val_loss=0.6023\n",
      "[Epoch 014] train_loss=0.2503, val_loss=0.6022\n",
      "[Epoch 015] train_loss=0.2501, val_loss=0.6024\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "alpha = 5.0   # 결과/수익률 구간에 줄 가중치 (5배부터 시도)\n",
    "epochs = 15\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "accum_steps = 4  # 그대로\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # ----- Train -----\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (x, y, mask, roi) in enumerate(train_loader, start=1):\n",
    "        x    = x.to(device)        # (B, T)\n",
    "        y    = y.to(device)        # (B, T)  pad는 -100\n",
    "        mask = mask.to(device)     # (B, T)\n",
    "        roi  = roi.to(device)      # (B, T)\n",
    "\n",
    "        logits = model(x, attn_mask=mask)  # (B, T, vocab)\n",
    "        B, T, V = logits.size()\n",
    "\n",
    "        # 1) 펼치기\n",
    "        logits_flat = logits.view(-1, V)   # (B*T, V)\n",
    "        y_flat      = y.view(-1)          # (B*T,)\n",
    "        roi_flat    = roi.view(-1).float()\n",
    "\n",
    "        # 2) 토큰별 CE loss (pad는 ignore_index=-100)\n",
    "        per_token_loss = F.cross_entropy(\n",
    "            logits_flat,\n",
    "            y_flat,\n",
    "            reduction=\"none\",\n",
    "            ignore_index=-100,\n",
    "        )  # (B*T,)\n",
    "\n",
    "        # 3) pad 아닌 위치\n",
    "        non_pad_mask = (y_flat != -100).float()   # pad면 0, 나머지 1\n",
    "\n",
    "        # 4) 가중치 만들기: 기본 1, roi 구간은 alpha배\n",
    "        base_w  = non_pad_mask\n",
    "        weights = base_w + roi_flat * (alpha - 1.0)\n",
    "        # pad 위치는 base_w=0 이라 그대로 0\n",
    "\n",
    "        # 5) 최종 loss: 가중 평균\n",
    "        loss = (per_token_loss * weights).sum() / (weights.sum() + 1e-8)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # gradient accumulation\n",
    "        loss = loss / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if step % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    else:\n",
    "        if (step % accum_steps) != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ----- Validation (여기는 가중치 없이, pad만 무시) -----\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, mask, roi in val_loader:\n",
    "            x    = x.to(device)\n",
    "            y    = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            logits = model(x, attn_mask=mask)\n",
    "            B, T, V = logits.size()\n",
    "\n",
    "            logits_flat = logits.view(-1, V)\n",
    "            y_flat      = y.view(-1)\n",
    "\n",
    "            per_token_loss = F.cross_entropy(\n",
    "                logits_flat,\n",
    "                y_flat,\n",
    "                reduction=\"none\",\n",
    "                ignore_index=-100,\n",
    "            )\n",
    "\n",
    "            non_pad_mask = (y_flat != -100).float()\n",
    "            loss = (per_token_loss * non_pad_mask).sum() / (non_pad_mask.sum() + 1e-8)\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {epoch:03d}] train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"lotto_gpt_epoch{epoch:03d}.pt\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"lotto_gpt_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4f961da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"train_loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87d375b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 65])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=5000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=5\n",
      "구매번호:\n",
      "[1,2,3,4,5,6]\n",
      "[11,13,19,27,36,43]\n",
      "[13,27,29,40,41,45]\n",
      "[8,11,13,21,28,41]\n",
      "[12,20,23,33,35,40]\n",
      "3개일치 (5000원) = 1\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=100.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=5000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    "    \"티켓수=5\\n\"\n",
    "    \"구매번호:\\n\"\n",
    "    \"[1,2,3,4,5,6]\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "219f7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "checkpoint loaded from: lotto_gpt_best.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "# 체크포인트 로드 (파일 이름 맞게 수정 가능)\n",
    "ckpt_path = \"lotto_gpt_best.pt\"   # 또는 \"lotto_gpt_epoch030.pt\" 등\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "print(\"checkpoint loaded from:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ba4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 25])\n",
      "model max_len: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE GENERATION ===\n",
      "money=1000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=1\n",
      "구매번호:\n",
      "[4,14,18,19,21,36]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=1000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
