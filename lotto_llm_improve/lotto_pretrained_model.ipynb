{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1035248d",
   "metadata": {},
   "source": [
    "# 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bd9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수 : 72\n",
      "토큰수 : 15\n",
      "[220, 543, 5850, 7342, 6129, 1088, 262, 2119, 24433, 339, 991, 550, 465, 1336, 82]\n",
      "  which Harry watched fly around the room wishing he still had his fulls\n",
      "220 :  \n",
      "543 :  which\n",
      "5850 :  Harry\n",
      "7342 :  watched\n",
      "6129 :  fly\n",
      "1088 :  around\n",
      "262 :  the\n",
      "2119 :  room\n",
      "24433 :  wishing\n",
      "339 :  he\n",
      "991 :  still\n",
      "550 :  had\n",
      "465 :  his\n",
      "1336 :  full\n",
      "82 : s\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"  which Harry watched fly around the room wishing he still had his fulls\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수 :\", len(text))  # 글자수: 26\n",
    "print(\"토큰수 :\", len(tokens))  # 토큰수: 6\n",
    "print(tokens)  # [15496, 2159, 257, 281, 3453, 13]\n",
    "print(tokenizer.decode(tokens))  # Harry Potter was a wizard.\n",
    "for token in tokens:\n",
    "    print(token, \":\", tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e8c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\github\\llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n",
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. GPT-2 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 2. GPT-2는 기본 pad_token이 없어서 직접 설정\n",
    "# if tokenizer.pad_token is None:\n",
    "#     special_tokens_dict = {'pad_token': '<|pad|>'}\n",
    "#     num_added = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# pad를 따로 추가하지 말고, eos를 그대로 pad로 사용\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pad_id = tokenizer.pad_token_id  # == eos_id\n",
    "\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d61185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 150000\n",
      "원본 샘플:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나 넣어놨으니까 \"\\n\\n\" 기준으로 자름\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"샘플 개수:\", len(train_samples))\n",
    "\n",
    "example = train_samples[0]\n",
    "print(\"원본 샘플:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e9b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 512])\n",
      "attention_mask shape: torch.Size([1, 512])\n",
      "디코딩된 텍스트:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "max_len = 512  # 임시\n",
    "\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=max_len,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",  # PyTorch 텐서로\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"]        # shape: (1, max_len)\n",
    "attention_mask = enc[\"attention_mask\"]  # shape: (1, max_len)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# 디코딩해서 잘 복원되는지 확인\n",
    "decoded = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "print(\"디코딩된 텍스트:\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1432b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class LottoDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len: int, focus_len: int = 118):\n",
    "        \"\"\"\n",
    "        focus_len: 시퀀스 뒤에서부터 몇 개 토큰을\n",
    "                   '결과/수익률 구간'이라고 보고 가중치를 줄지\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.eos = tokenizer.eos_token\n",
    "        self.focus_len = focus_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_txt = self.texts[idx]\n",
    "\n",
    "        txt = row_txt + self.eos\n",
    "\n",
    "        # max_len+1 길이로 토큰화 → x:[:-1], y:[1:] 사용\n",
    "        enc = self.tokenizer(\n",
    "            txt,\n",
    "            max_length=self.max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn_mask = enc[\"attention_mask\"][0]  # (max_len+1,)\n",
    "\n",
    "        # 언어모델용 input/target\n",
    "        x = ids[:-1].clone()       # (max_len,)\n",
    "        y = ids[1:].clone()        # (max_len,)\n",
    "        x_mask = attn_mask[:-1].clone()\n",
    "\n",
    "        # pad 위치는 loss에서 무시되도록 -100\n",
    "        y[x_mask == 0] = -100\n",
    "\n",
    "        # ----- roi_mask 생성 (결과/수익률 구간) -----\n",
    "        # 실제 토큰 길이 (pad 제외)\n",
    "        valid_len = int(x_mask.sum().item())   # 예: 380 토큰\n",
    "        roi_mask = torch.zeros_like(x_mask)    # (max_len,)\n",
    "\n",
    "        # 뒤에서 focus_len개를 결과 구간으로 설정\n",
    "        start = max(0, valid_len - self.focus_len)\n",
    "        roi_mask[start:valid_len] = 1\n",
    "\n",
    "        return x, y, x_mask, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e2f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([512])\n",
      "y shape: torch.Size([512])\n",
      "x_mask shape: torch.Size([512])\n",
      "roi_mask shape: torch.Size([512])\n",
      "x[:20]: tensor([26316,    28, 27559,   198, 14463,    28,    16,    11,  1157,    11,\n",
      "         1314,    11,  1507,    11,  1959,    11,  2548,   198,  4189,   385])\n",
      "y[:20]: tensor([   28, 27559,   198, 14463,    28,    16,    11,  1157,    11,  1314,\n",
      "           11,  1507,    11,  1959,    11,  2548,   198,  4189,   385,    28])\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "train_ds = LottoDataset(train_samples, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "x, y, x_mask, roi_mask = train_ds[0]\n",
    "\n",
    "print(\"x shape:\", x.shape)          # torch.Size([256])\n",
    "print(\"y shape:\", y.shape)          # torch.Size([256])\n",
    "print(\"x_mask shape:\", x_mask.shape)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)\n",
    "\n",
    "print(\"x[:20]:\", x[:20])\n",
    "print(\"y[:20]:\", y[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f8c7",
   "metadata": {},
   "source": [
    "DataSet 출력값 예시\n",
    "\n",
    "X TEXT:\n",
    "money=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "\n",
    "Y TEXT:\n",
    "oney=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a468413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|>\n",
      "pad_token_id: 50256\n",
      "vocab_size: 50257\n",
      "\n",
      "input_ids shape: torch.Size([512])\n",
      "attention_mask shape: torch.Size([512])\n",
      "\n",
      "=== DECODED TEXT ===\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "\n",
    "\n",
    "# lotto_train.txt 읽기\n",
    "def load_text_samples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "\n",
    "# 샘플 하나\n",
    "example = train_samples[0]\n",
    "# print(\"=== ORIGINAL TEXT ===\")\n",
    "# print(example)\n",
    "\n",
    "# encode\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"][0]\n",
    "attention_mask = enc[\"attention_mask\"][0]\n",
    "\n",
    "print(\"\\ninput_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# decode\n",
    "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== DECODED TEXT ===\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4947dc",
   "metadata": {},
   "source": [
    "# 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ae71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 샘플 수: 150000\n",
      "첫 샘플 원본:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나씩 있다고 가정 → \"\\n\\n\" 기준 split\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"train 샘플 수:\", len(train_texts))\n",
    "print(\"첫 샘플 원본:\")\n",
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a8db334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([4, 512])\n",
      "y_batch shape: torch.Size([4, 512])\n",
      "mask_batch shape: torch.Size([4, 512])\n",
      "roi_mask shape: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 512  # 일단 256 정도로 가정\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 배치 하나만 꺼내서 확인해보자\n",
    "x_batch, y_batch, mask_batch, roi_mask = next(iter(train_loader))\n",
    "\n",
    "print(\"x_batch shape:\", x_batch.shape)        # (B, T) = (4, 256)\n",
    "print(\"y_batch shape:\", y_batch.shape)        # (4, 256)\n",
    "print(\"mask_batch shape:\", mask_batch.shape)  # (4, 256)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)      # (4, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fabdab",
   "metadata": {},
   "source": [
    "### focus_len 마지막 증가할 가중치 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e711222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_focus_len(texts, tokenizer, max_len: int, \n",
    "                       target_tokens=(\"3개일치\", \"수익률\"),\n",
    "                       sample_size: int = 1000,\n",
    "                       quantile: float = 0.95):\n",
    "    \"\"\"\n",
    "    texts: lotto_train.txt에서 읽어온 전체 텍스트 리스트\n",
    "    target_tokens: 결과/수익률 블록을 대표하는 토큰 문자열들\n",
    "    sample_size: 몇 개 샘플만 뽑아서 통계 낼지\n",
    "    quantile: 상위 몇 %까지 커버할지 (0.95면 95퍼센타일)\n",
    "    \"\"\"\n",
    "    n = min(len(texts), sample_size)\n",
    "    lengths = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row_txt = texts[i]\n",
    "        txt = row_txt + tokenizer.eos_token\n",
    "\n",
    "        enc = tokenizer(\n",
    "            txt,\n",
    "            max_length=max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn = enc[\"attention_mask\"][0]     # (max_len+1,)\n",
    "\n",
    "        valid_len = int(attn.sum().item())\n",
    "        ids_list = ids[:valid_len].tolist()\n",
    "\n",
    "        # 이 샘플에서 결과 블록 시작 위치를 찾는다\n",
    "        start_idx = valid_len  # 기본값: 못 찾으면 tail=0\n",
    "\n",
    "        for tok_str in target_tokens:\n",
    "            pat = tokenizer(tok_str, add_special_tokens=False)[\"input_ids\"]\n",
    "            L = len(pat)\n",
    "\n",
    "            for j in range(valid_len - L + 1):\n",
    "                if ids_list[j:j+L] == pat:\n",
    "                    start_idx = min(start_idx, j)\n",
    "                    break  # 이 토큰은 찾았으니 다음 토큰으로\n",
    "\n",
    "        tail_len = valid_len - start_idx\n",
    "        if tail_len < 0:\n",
    "            tail_len = 0\n",
    "\n",
    "        lengths.append(tail_len)\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "    print(\"샘플 개수:\", len(lengths))\n",
    "    print(\"min tail_len:\", lengths.min())\n",
    "    print(\"avg tail_len:\", lengths.mean())\n",
    "    print(\"max tail_len:\", lengths.max())\n",
    "    focus_len = int(np.quantile(lengths, quantile))\n",
    "    print(f\"{int(quantile*100)} 퍼센타일 tail_len:\", focus_len)\n",
    "\n",
    "    return focus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fee5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 1000\n",
      "min tail_len: 117\n",
      "avg tail_len: 117.176\n",
      "max tail_len: 120\n",
      "95 퍼센타일 tail_len: 118\n",
      "최종 선택된 focus_len = 118\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")\n",
    "\n",
    "focus_len = estimate_focus_len(\n",
    "    train_texts,\n",
    "    tokenizer,\n",
    "    max_len=max_len,\n",
    "    target_tokens=(\"3개일치\", \"수익률\"),\n",
    "    sample_size=1000,\n",
    "    quantile=0.95,\n",
    ")\n",
    "print(\"최종 선택된 focus_len =\", focus_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818c09",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43da2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class GPTConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        n_layer: int = 4,\n",
    "        n_head: int = 4,\n",
    "        d_model: int = 256,\n",
    "        d_ff: int = 1024,\n",
    "        max_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.max_len = max_len\n",
    "        self.dropout = dropout\n",
    "        self.pad_id = pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bac05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.d_model = config.d_model\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.qkv = nn.Linear(config.d_model, 3 * config.d_model)\n",
    "        self.proj = nn.Linear(config.d_model, config.d_model)\n",
    "\n",
    "        mask = torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\",\n",
    "            mask.view(1, 1, config.max_len, config.max_len)\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        head_dim = C // H\n",
    "\n",
    "        qkv = self.qkv(x)              # (B, T, 3C)\n",
    "        q, k, v = qkv.split(C, dim=2)  # (B, T, C) each\n",
    "\n",
    "        q = q.view(B, T, H, head_dim).transpose(1, 2)  # (B, H, T, head_dim)\n",
    "        k = k.view(B, T, H, head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, H, head_dim).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / (head_dim ** 0.5)  # (B, H, T, T)\n",
    "\n",
    "        causal_mask = self.causal_mask[:, :, :T, :T]\n",
    "        att = att.masked_fill(causal_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: (B, T) → (B, 1, 1, T)\n",
    "            pad_mask = attn_mask.view(B, 1, 1, T)\n",
    "            att = att.masked_fill(pad_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "\n",
    "        y = att @ v                    # (B, H, T, head_dim)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fea54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.d_ff, config.d_model),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = x + self.attn(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26fea343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        self.pos_emb = nn.Embedding(config.max_len, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(config.n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        self.head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "\n",
    "        # (선택) 입력 임베딩과 출력 head weight tying\n",
    "        self.head.weight = self.tok_emb.weight\n",
    "\n",
    "    def forward(self, idx, attn_mask=None):\n",
    "        # idx: (B, T)\n",
    "        B, T = idx.size()\n",
    "        device = idx.device\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device)\n",
    "        pos = pos.unsqueeze(0).expand(B, T)  # (B, T)\n",
    "\n",
    "        x = self.tok_emb(idx) + self.pos_emb(pos)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b44d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, tokenizer, prompt: str, max_new_tokens: int = 200, device=\"cpu\"):\n",
    "    \n",
    "    model.eval()\n",
    "    max_len = model.config.max_len\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # 1) 처음에는 패딩 없이 실제 길이만큼만 인코딩\n",
    "    enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    x = enc[\"input_ids\"].to(device)      # (1, T0)\n",
    "    attn_mask = enc[\"attention_mask\"].to(device)  # (1, T0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 2) 모델에 넣기 전에 길이가 max_len을 넘으면 뒤에서 max_len만 유지\n",
    "        if x.size(1) > max_len:\n",
    "            x = x[:, -max_len:]\n",
    "            attn_mask = attn_mask[:, -max_len:]\n",
    "\n",
    "        # 3) forward\n",
    "        logits = model(x, attn_mask=attn_mask)        # (1, T, vocab)\n",
    "        last_logits = logits[:, -1, :]                # (1, vocab)\n",
    "\n",
    "        probs = torch.softmax(last_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "        next_token = next_id.item()\n",
    "\n",
    "        if next_token == eos_token_id:\n",
    "            break\n",
    "\n",
    "        # 4) 새 토큰 이어붙이기\n",
    "        x = torch.cat([x, next_id], dim=1)  # (1, T+1)\n",
    "        next_mask = torch.ones_like(next_id, device=device)\n",
    "        attn_mask = torch.cat([attn_mask, next_mask], dim=1)\n",
    "\n",
    "    # 5) 결과 디코딩\n",
    "    out_ids = x[0].tolist()\n",
    "    text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4de740e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "train samples: 150000\n",
      "val samples: 15000\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 2) 데이터 로딩\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")  # 없다면 주석 처리하고 train만 써도 됨\n",
    "\n",
    "print(\"train samples:\", len(train_texts))\n",
    "print(\"val samples:\", len(val_texts))\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "val_ds = LottoDataset(val_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "# 3) 모델 & optimizer & loss\n",
    "config = GPTConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    d_model=256,\n",
    "    d_ff=1024,\n",
    "    max_len=max_len,\n",
    "    dropout=0.1,\n",
    "    pad_id=pad_id,\n",
    ")\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81b8fe",
   "metadata": {},
   "source": [
    "# Eos 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e978db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9653984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n",
      "\n",
      "DATASET 내부 tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL tokenizer:\")\n",
    "print(\"  pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)\n",
    "\n",
    "print(\"\\nDATASET 내부 tokenizer:\")\n",
    "print(\"  pad_token:\", train_ds.tokenizer.pad_token, \"id:\", train_ds.tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", train_ds.tokenizer.eos_token, \"id:\", train_ds.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab8a79",
   "metadata": {},
   "source": [
    "#학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9223e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=0.7677, val_loss=0.7206\n",
      "[Epoch 002] train_loss=0.1722, val_loss=0.6180\n",
      "[Epoch 003] train_loss=0.1546, val_loss=0.6101\n",
      "[Epoch 004] train_loss=0.1516, val_loss=0.6078\n",
      "[Epoch 005] train_loss=0.1505, val_loss=0.6074\n",
      "[Epoch 006] train_loss=0.1498, val_loss=0.6068\n",
      "[Epoch 007] train_loss=0.1494, val_loss=0.6065\n",
      "[Epoch 008] train_loss=0.1491, val_loss=0.6058\n",
      "[Epoch 009] train_loss=0.1490, val_loss=0.6060\n",
      "[Epoch 010] train_loss=0.1488, val_loss=0.6059\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "pad_target_id = -100        # y에서 pad 자리에 들어있는 값\n",
    "alpha = 10.0                 # 결과/수익률 구간 가중치 배율\n",
    "epochs = 10 \n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "accum_steps = 4  # 그대로 (batch 8 * 4 = effective 32)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # ----- Train -----\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (x, y, mask, roi) in enumerate(train_loader, start=1):\n",
    "        x    = x.to(device)       # (B, T)\n",
    "        y    = y.to(device)       # (B, T)  pad는 -100\n",
    "        mask = mask.to(device)    # (B, T)\n",
    "        roi  = roi.to(device)     # (B, T)\n",
    "\n",
    "        logits = model(x, attn_mask=mask)   # (B, T, vocab)\n",
    "        B, T, V = logits.size()\n",
    "\n",
    "        # 1) 펼치기\n",
    "        logits_flat = logits.view(-1, V)    # (B*T, V)\n",
    "        y_flat      = y.view(-1)           # (B*T,)\n",
    "        roi_flat    = roi.view(-1).float() # (B*T,)\n",
    "\n",
    "        # 2) 토큰별 CE loss (pad는 ignore_index=-100)\n",
    "        per_token_loss = F.cross_entropy(\n",
    "            logits_flat,\n",
    "            y_flat,\n",
    "            reduction=\"none\",\n",
    "            ignore_index=pad_target_id,\n",
    "        )  # (B*T,)\n",
    "\n",
    "        # 3) pad 아닌 위치 마스크\n",
    "        non_pad_mask = (y_flat != pad_target_id).float()  # pad면 0, 나머지 1\n",
    "\n",
    "        # roi가 pad 위치를 건드리지 않도록 한 번 더 마스킹\n",
    "        roi_flat = roi_flat * non_pad_mask\n",
    "\n",
    "        # 4) 가중치: 기본 1, roi 구간은 alpha배\n",
    "        base_w  = non_pad_mask                  # pad: 0, 나머지: 1\n",
    "        weights = base_w + roi_flat * (alpha - 1.0)\n",
    "        # -> roi_flat=1이면 1+(α-1)=α, roi_flat=0이면 1\n",
    "\n",
    "        # 5) 최종 loss: 가중 평균\n",
    "        loss = (per_token_loss * weights).sum() / (weights.sum() + 1e-8)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # gradient accumulation\n",
    "        loss = loss / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if step % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    else:\n",
    "        # 마지막에 accum_steps로 딱 안 나누어떨어지는 경우 방어 코드\n",
    "        if (step % accum_steps) != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ----- Validation (여기는 가중치 없이, pad만 무시) -----\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, mask, roi in val_loader:\n",
    "            x    = x.to(device)\n",
    "            y    = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            logits = model(x, attn_mask=mask)\n",
    "            B, T, V = logits.size()\n",
    "\n",
    "            logits_flat = logits.view(-1, V)\n",
    "            y_flat      = y.view(-1)\n",
    "\n",
    "            per_token_loss = F.cross_entropy(\n",
    "                logits_flat,\n",
    "                y_flat,\n",
    "                reduction=\"none\",\n",
    "                ignore_index=pad_target_id,\n",
    "            )\n",
    "\n",
    "            non_pad_mask = (y_flat != pad_target_id).float()\n",
    "            val_loss = (per_token_loss * non_pad_mask).sum() / (non_pad_mask.sum() + 1e-8)\n",
    "            val_loss_sum += val_loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {epoch:03d}] train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # ----- 체크포인트 -----\n",
    "    torch.save(model.state_dict(), f\"lotto_gpt_epoch{epoch:03d}.pt\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"lotto_gpt_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4f961da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[43mepochs\u001b[49m + \u001b[32m1\u001b[39m), train_losses, label=\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m), val_losses, label=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'epochs' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"train_loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87d375b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 25])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=5000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    "    # \"티켓수=5\\n\"\n",
    "    # \"구매번호:\\n\"\n",
    "    # \"[1,2,3,4,5,6]\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "219f7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "checkpoint loaded from: lotto_gpt_best.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "# 체크포인트 로드 (파일 이름 맞게 수정 가능)\n",
    "ckpt_path = \"lotto_gpt_best.pt\"   # 또는 \"lotto_gpt_epoch030.pt\" 등\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "print(\"checkpoint loaded from:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1ba4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 25])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=1000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=1\n",
      "구매번호:\n",
      "[5,18,24,29,31,35]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=1000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68219565",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Test Data set을 이용하여 구간별 정답률 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "325c451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test blocks: 15000\n",
      "첫 블록:\n",
      " money=7000\n",
      "winning=7,24,27,29,39,45\n",
      "bonus=1\n",
      "###\n",
      "티켓수=7\n",
      "구매번호:\n",
      "[7,9,12,18,28,38]\n",
      "[4,14,17,18,28,30]\n",
      "[5,6,14,16,23,32]\n",
      "[3,16,20,22,34,35]\n",
      "[4,8,11,14,16,23]\n",
      "[7,24,28,29,39,45]\n",
      "[7,16,22,24,28,30]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 1\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=21428.6%\n"
     ]
    }
   ],
   "source": [
    "def load_blocks(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "    # 빈 줄 기준으로 블록 나누기\n",
    "    raw_blocks = text.split(\"\\n\\n\")\n",
    "    # 공백만 있는 블록 제거\n",
    "    blocks = [b.strip() for b in raw_blocks if b.strip()]\n",
    "    return blocks\n",
    "\n",
    "test_blocks = load_blocks(\"lotto_test.txt\")\n",
    "print(\"test blocks:\", len(test_blocks))\n",
    "print(\"첫 블록:\\n\", test_blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a545455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SET용 프롬프트 예시 ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'money=7000\\nwinning=7,24,27,29,39,45\\nbonus=1\\n###\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prompt_for_testset(block: str) -> str:\n",
    "    \"\"\"\n",
    "    블록에서 티켓 생성용 프롬프트 부분만 추출\n",
    "    \"\"\"\n",
    "    lines = block.splitlines()\n",
    "    prompt_lines = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"money=\") or line.startswith(\"winning=\") or line.startswith(\"bonus=\"):\n",
    "            prompt_lines.append(line)\n",
    "        elif line.strip() == \"###\":\n",
    "            prompt_lines.append(line)\n",
    "            break  # ### 이후는 티켓 정보이므로 중단\n",
    "    prompt = \"\\n\".join(prompt_lines) + \"\\n\"\n",
    "    return prompt\n",
    "\n",
    "print(\"=== TEST SET용 프롬프트 예시 ===\")\n",
    "get_prompt_for_testset(test_blocks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbca1e6",
   "metadata": {},
   "source": [
    "### 형식검사\n",
    "\n",
    "- parse_ticket_count(block) -> int | None\n",
    "- check_ticket_lines_format(block) -> dict | None\n",
    "- parse_result_labels(block) -> dict | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa08c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_ticket_count(block: str):\n",
    "    \"\"\"\n",
    "    '티켓수=숫자' 에서 숫자만 뽑는다.\n",
    "    없거나 정수가 아니면 None 반환.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"티켓수\\s*=\\s*([0-9]+)\", block)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return int(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "print(parse_ticket_count(test_blocks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "047f3366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_section': True, 'ticket_lines': ['[7,9,12,18,28,38]', '[4,14,17,18,28,30]', '[5,6,14,16,23,32]', '[3,16,20,22,34,35]', '[4,8,11,14,16,23]', '[7,24,28,29,39,45]', '[7,16,22,24,28,30]'], 'parsed_numbers': [[7, 9, 12, 18, 28, 38], [4, 14, 17, 18, 28, 30], [5, 6, 14, 16, 23, 32], [3, 16, 20, 22, 34, 35], [4, 8, 11, 14, 16, 23], [7, 24, 28, 29, 39, 45], [7, 16, 22, 24, 28, 30]]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_ticket_lines_format(block: str):\n",
    "    \"\"\"\n",
    "    1-2. 구매번호 줄 형식 검사\n",
    "    - '구매번호:' 라인이 존재하는지\n",
    "    - 그 아래에 [...] 형태 줄들이 있는지\n",
    "    - 각 줄에서 숫자를 파싱할 수 있는지\n",
    "\n",
    "    반환:\n",
    "        {\n",
    "            \"has_section\": True/False,        # 구매번호: 라인 존재 여부\n",
    "            \"ticket_lines\": [...],            # 실제 [...] 형태 줄 리스트\n",
    "            \"parsed_numbers\": [[...], ...],   # 각 줄 숫자 리스트\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    lines = block.splitlines()\n",
    "    has_section = False\n",
    "    start = None\n",
    "\n",
    "    # 1) 구매번호: 찾기\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.strip() == \"구매번호:\":\n",
    "            has_section = True\n",
    "            start = idx + 1\n",
    "            break\n",
    "\n",
    "    if not has_section:\n",
    "        return {\n",
    "            \"has_section\": False,\n",
    "            \"ticket_lines\": [],\n",
    "            \"parsed_numbers\": [],\n",
    "        }\n",
    "\n",
    "    # 2) 구매번호 아래 줄들 수집\n",
    "    ticket_lines = []\n",
    "    for line in lines[start:]:\n",
    "        s = line.strip()\n",
    "        # 결과 항목 나오면 구매번호 section 끝난 것으로 간주\n",
    "        if s.startswith(\"3개일치\") or s.startswith(\"4개일치\") or s.startswith(\"5개일치\") or s.startswith(\"6개일치\") or s.startswith(\"수익률\"):\n",
    "            break\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            ticket_lines.append(s)\n",
    "\n",
    "    # 3) 숫자 파싱\n",
    "    parsed = []\n",
    "    try:\n",
    "        for t in ticket_lines:\n",
    "            nums = re.findall(r\"\\d+\", t)\n",
    "            parsed.append([int(n) for n in nums])\n",
    "    except ValueError:\n",
    "        return {\n",
    "            \"has_section\": True,\n",
    "            \"ticket_lines\": ticket_lines,\n",
    "            \"parsed_numbers\": []\n",
    "        }\n",
    "    return {\n",
    "        \"has_section\": True,\n",
    "        \"ticket_lines\": ticket_lines,\n",
    "        \"parsed_numbers\": parsed,\n",
    "    }\n",
    "        \n",
    "print(check_ticket_lines_format(test_blocks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2b1a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m3': 0, 'm4': 0, 'm5': 1, 'm5b': 0, 'm6': 0, 'roi': 21428.6}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_result_labels(block: str):\n",
    "    \"\"\"\n",
    "    1-3. 라벨(결과) 줄 형식 검사 + 파싱\n",
    "    아래 6개가 모두 존재하고 숫자로 파싱되면 dict 반환,\n",
    "    하나라도 없거나 숫자 변환 실패하면 None 반환.\n",
    "\n",
    "      3개일치 (...) = X\n",
    "      4개일치 (...) = Y\n",
    "      5개일치 (...) = Z\n",
    "      5개보너스일치 (...) = A\n",
    "      6개일치 (...) = B\n",
    "      수익률 = R%\n",
    "    \"\"\"\n",
    "\n",
    "    m3  = re.search(r\"3개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", block)\n",
    "    m4  = re.search(r\"4개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", block)\n",
    "    m5  = re.search(r\"5개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", block)\n",
    "    m5b = re.search(r\"5개보너스일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", block)\n",
    "    m6  = re.search(r\"6개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", block)\n",
    "    mroi = re.search(r\"수익률\\s*=?\\s*([-+]?\\d+(?:\\.\\d+)?)\\s*%\", block)\n",
    "\n",
    "    # 하나라도 없으면 형식 실패\n",
    "    if not all([m3, m4, m5, m5b, m6, mroi]):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        labels = {\n",
    "            \"m3\":  int(m3.group(1)),\n",
    "            \"m4\":  int(m4.group(1)),\n",
    "            \"m5\":  int(m5.group(1)),\n",
    "            \"m5b\": int(m5b.group(1)),\n",
    "            \"m6\":  int(m6.group(1)),\n",
    "            \"roi\": float(mroi.group(1)),  # 예: 21428.6\n",
    "        }\n",
    "    except ValueError:\n",
    "        # 숫자로 변환 안 되면 형식 실패\n",
    "        return None\n",
    "\n",
    "    return labels\n",
    "\n",
    "print(parse_result_labels(test_blocks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c8295",
   "metadata": {},
   "source": [
    "### 내부 일관성 확인(llm 출력안에서 검사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4251897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def check_ticket_count_consistency(N: int, list_ticket: list  ):\n",
    "    \"\"\"\n",
    "    N: 선언된 티켓수\n",
    "    M: 실제 구매번호 줄 개수\n",
    "    \"\"\"\n",
    "    return N == len(list_ticket)\n",
    "print(check_ticket_count_consistency(5, [[1,2,3,4,5,6], [7,8,9,10,11,12]]))  # False\n",
    "print(check_ticket_count_consistency(2, [[1,2,3,4,5,6], [7,8,9,10,11,12]]))  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf292365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def validate_ticket_numbers(parsed_numbers):\n",
    "    \"\"\"\n",
    "    parsed_numbers: [[...], [...], ...]\n",
    "\n",
    "    반환:\n",
    "      (invalid_count, duplicate_count, out_of_range_count)\n",
    "    \"\"\"\n",
    "\n",
    "    invalid_count = 0\n",
    "    duplicate_count = 0\n",
    "    out_of_range_count = 0\n",
    "\n",
    "    for nums in parsed_numbers:\n",
    "        # 개수 검사\n",
    "        if len(nums) != 6:\n",
    "            invalid_count += 1\n",
    "\n",
    "        # 중복 검사\n",
    "        if len(set(nums)) != len(nums):\n",
    "            duplicate_count += 1\n",
    "\n",
    "        # 범위 검사\n",
    "        for n in nums:\n",
    "            if n < 1 or n > 45:\n",
    "                out_of_range_count += 1\n",
    "                break\n",
    "\n",
    "    return invalid_count, duplicate_count, out_of_range_count\n",
    "print(validate_ticket_numbers([[1,2,3,4,5,6], [7,8,9,10,11,11], [0,2,3,4,5,6], [1,2,3]]))  # (1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef15d8e",
   "metadata": {},
   "source": [
    "### 계산 정확도 레벨 (기능 테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fdd3fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, False)\n",
      "(2, True)\n"
     ]
    }
   ],
   "source": [
    "def count_matches(ticket, winning_numbers, bonus_number):\n",
    "    \"\"\"\n",
    "    ticket: [n1, n2, ..., n6]\n",
    "    winning_numbers: [w1, ..., w6]\n",
    "    bonus_number: int\n",
    "    \"\"\"\n",
    "    win_set = set(winning_numbers)\n",
    "    match_cnt = sum(1 for n in ticket if n in win_set)\n",
    "    bonus_match = bonus_number in ticket\n",
    "    return match_cnt, bonus_match\n",
    "print(count_matches([1,2,3,4,5,6], [4,5,6,7,8,9], 10))  # (3, False)\n",
    "print(count_matches([1,2,3,4,5,10], [4,5,6,7,8,9], 10))  # (2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5f3bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m3': 1, 'm4': 0, 'm5': 0, 'm5b': 0, 'm6': 1}\n"
     ]
    }
   ],
   "source": [
    "def compute_match_stats(tickets, winning_numbers, bonus_number):\n",
    "    \"\"\"\n",
    "    tickets: [[...], [...], ...]\n",
    "    반환: {\"m3\": x, \"m4\": y, \"m5\": z, \"m5b\": a, \"m6\": b}\n",
    "    \"\"\"\n",
    "\n",
    "    stats = {\"m3\": 0, \"m4\": 0, \"m5\": 0, \"m5b\": 0, \"m6\": 0}\n",
    "\n",
    "    for t in tickets:\n",
    "        match_cnt, bonus_match = count_matches(t, winning_numbers, bonus_number)\n",
    "\n",
    "        if match_cnt == 3:\n",
    "            stats[\"m3\"] += 1\n",
    "        elif match_cnt == 4:\n",
    "            stats[\"m4\"] += 1\n",
    "        elif match_cnt == 5 and bonus_match:\n",
    "            stats[\"m5b\"] += 1\n",
    "        elif match_cnt == 5:\n",
    "            stats[\"m5\"] += 1\n",
    "        elif match_cnt == 6:\n",
    "            stats[\"m6\"] += 1\n",
    "\n",
    "    return stats\n",
    "print(compute_match_stats([[1,2,3,4,5,6], [4,5,6,7,8,9], [1,2,3,4,5,10]], [4,5,6,7,8,9], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "466acf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, True, True, True)\n"
     ]
    }
   ],
   "source": [
    "def check_match_stats(tickets, winning_numbers, bonus_number, labels):\n",
    "    \"\"\"\n",
    "    tickets: LLM이 출력한 구매번호 리스트 (parsed_numbers)\n",
    "    winning_numbers, bonus_number: 데이터셋에서 가져온 당첨 정보\n",
    "    labels: parse_result_labels(block) 결과 dict (m3~m6 포함)\n",
    "\n",
    "    반환:\n",
    "      (m3_ok, m4_ok, m5_ok, m5b_ok, m6_ok)\n",
    "    \"\"\"\n",
    "\n",
    "    stats = compute_match_stats(tickets, winning_numbers, bonus_number)\n",
    "\n",
    "    m3_ok  = (stats[\"m3\"]  == labels.get(\"m3\"))\n",
    "    m4_ok  = (stats[\"m4\"]  == labels.get(\"m4\"))\n",
    "    m5_ok  = (stats[\"m5\"]  == labels.get(\"m5\"))\n",
    "    m5b_ok = (stats[\"m5b\"] == labels.get(\"m5b\"))\n",
    "    m6_ok  = (stats[\"m6\"]  == labels.get(\"m6\"))\n",
    "\n",
    "    return m3_ok, m4_ok, m5_ok, m5b_ok, m6_ok\n",
    "print(check_match_stats(\n",
    "    [[1,2,3,4,5,6], [4,5,6,7,8,9], [1,2,3,4,5,10]],\n",
    "    [4,5,6,7,8,9],  10,\n",
    "    {\"m3\":1, \"m4\":0, \"m5\":0, \"m5b\":0, \"m6\":1}\n",
    "))  # (True, True, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_roi_exact(labels, money):\n",
    "    \"\"\"\n",
    "    labels: {\n",
    "        \"m3\": X,\n",
    "        \"m4\": Y,\n",
    "        \"m5\": Z,\n",
    "        \"m5b\": A,\n",
    "        \"m6\": B,\n",
    "        \"roi\": R\n",
    "    }\n",
    "    money: 총 사용 금액\n",
    "\n",
    "    return: True / False\n",
    "    \"\"\"\n",
    "\n",
    "    # 상금 규칙\n",
    "    reward = (\n",
    "        labels[\"m3\"]  * 5000 +\n",
    "        labels[\"m4\"]  * 50000 +\n",
    "        labels[\"m5\"]  * 1500000 +\n",
    "        labels[\"m5b\"] * 30000000 +\n",
    "        labels[\"m6\"]  * 2000000000\n",
    "    )\n",
    "\n",
    "    # 계산 수익률\n",
    "    calc_roi = (reward / money) * 100\n",
    "\n",
    "    # LLM이 쓴 수익률\n",
    "    llm_roi = labels[\"roi\"]\n",
    "    print(\"asdf\",calc_roi, llm_roi)\n",
    "\n",
    "    return round(calc_roi, 1) == round(llm_roi, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c4d19edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_money_from_prompt(prompt: str):\n",
    "    m = re.search(r\"money\\s*=\\s*(\\d+)\", prompt)\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1))\n",
    "\n",
    "\n",
    "def parse_winning_and_bonus_from_prompt(prompt: str):\n",
    "    mwin = re.search(r\"winning=([0-9,]+)\", prompt)\n",
    "    mbonus = re.search(r\"bonus=(\\d+)\", prompt)\n",
    "\n",
    "    if not mwin or not mbonus:\n",
    "        return None, None\n",
    "\n",
    "    winning_numbers = list(map(int, mwin.group(1).split(\",\")))\n",
    "    bonus_number = int(mbonus.group(1))\n",
    "\n",
    "    return winning_numbers, bonus_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb8480",
   "metadata": {},
   "source": [
    "## 테스트 한줄 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "df57730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'format_ok': True, 'login_ok': True, 'errors': []}\n"
     ]
    }
   ],
   "source": [
    "def test_one_sample(input: str, block: str):\n",
    "    \"\"\"\n",
    "    테스트셋 블록 1개를 검사하는 함수.\n",
    "    기존에 만든 함수들만 호출한다.\n",
    "    \"\"\"\n",
    "    # print(input, \"\\n---\\n\", block)\n",
    "\n",
    "    results = {\n",
    "        \"ok\" : True,\n",
    "        \"format_ok\" : True,\n",
    "        \"logic_ok\" : True,\n",
    "        \"errors\": []\n",
    "    }\n",
    "\n",
    "    # 1-1. 티켓수 파싱\n",
    "    ticket_count = parse_ticket_count(block)\n",
    "\n",
    "    if ticket_count is None:\n",
    "        results[\"ok\"] = False\n",
    "        results[\"format_ok\"] = False\n",
    "        results[\"errors\"].append(\"ticket_count_parse_error\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # 1-2. 구매번호 줄 파싱\n",
    "    ticket_info = check_ticket_lines_format(block)\n",
    "    ticket_lines = ticket_info[\"ticket_lines\"]\n",
    "    parsed_numbers = ticket_info[\"parsed_numbers\"]\n",
    "\n",
    "    if not ticket_info[\"has_section\"] or not parsed_numbers:\n",
    "        results[\"ok\"] = False\n",
    "        results[\"format_ok\"] = False\n",
    "        results[\"errors\"].append(\"ticket_lines_format_error\")\n",
    "        return results\n",
    "    \n",
    "    # 1-3. 라벨 파싱\n",
    "    labels = parse_result_labels(block)\n",
    "\n",
    "    if labels is None:\n",
    "        results[\"ok\"] = False\n",
    "        results[\"format_ok\"] = False\n",
    "        results[\"errors\"].append(\"result_labels_parse_error\")\n",
    "        return results\n",
    "\n",
    "    # 2-1. 티켓수 일관성\n",
    "    ticket_count_match = check_ticket_count_consistency(ticket_count, parsed_numbers)\n",
    "    if not ticket_count_match:\n",
    "        results[\"ok\"] = False\n",
    "        results[\"format_ok\"] = False\n",
    "        results[\"errors\"].append(\"ticket_count_mismatch\")\n",
    "        return results\n",
    "\n",
    "    # 2-2. 구매번호 유효성\n",
    "    invalid_cnt, dup_cnt, range_cnt = validate_ticket_numbers(parsed_numbers)\n",
    "    if invalid_cnt > 0 or dup_cnt > 0 or range_cnt > 0:\n",
    "        results[\"ok\"] = False\n",
    "        results[\"format_ok\"] = False\n",
    "        results[\"errors\"].append(\"ticket_numbers_invalid\")\n",
    "        return results\n",
    "    \n",
    "    # 인풋데이터 추출\n",
    "    winning_numbers, bonus_number = parse_winning_and_bonus_from_prompt(input)\n",
    "    money = parse_money_from_prompt(input)\n",
    "\n",
    "    # 3-1. n개 일치 검증\n",
    "    m3_ok, m4_ok, m5_ok, m5b_ok, m6_ok = check_match_stats(\n",
    "        parsed_numbers,\n",
    "        winning_numbers,\n",
    "        bonus_number,\n",
    "        labels\n",
    "    )\n",
    "\n",
    "    error = []\n",
    "    match_check = all([m3_ok, m4_ok, m5_ok, m5b_ok, m6_ok])\n",
    "    if not match_check:\n",
    "        error.append(\"match_stats_mismatch\")\n",
    "    # 3-2. 수익률 검증\n",
    "    roi_ok = check_roi_exact(labels, money)\n",
    "    if not roi_ok:\n",
    "        error.append(\"roi_mismatch\")\n",
    "\n",
    "    # 결과 리턴 (단순하게)\n",
    "\n",
    "    if match_check and roi_ok:\n",
    "        return {\n",
    "            \"ok\": True,\n",
    "            \"format_ok\" : True,\n",
    "            \"login_ok\": True,\n",
    "            \"errors\": []\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"format_ok\" : True,\n",
    "            \"login_ok\": match_check and roi_ok,\n",
    "            \"errors\": error\n",
    "        }\n",
    "\n",
    "print(test_one_sample(get_prompt_for_testset(test_blocks[0]), test_blocks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6fe5e3",
   "metadata": {},
   "source": [
    "### 전체 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5f7158ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_testset(   \n",
    "        model,\n",
    "        tokenizer,\n",
    "        test_path: str = \"lotto_test.txt\",\n",
    "        device: str = \"cpu\",\n",
    "        max_samples: int = 100,\n",
    "        max_new_tokens: int = 256,\n",
    "    ):\n",
    "\n",
    "    blocks = load_blocks(test_path)\n",
    "\n",
    "    stats = {\n",
    "        \"n_total\": 0,\n",
    "        \"n_ok\": 0,\n",
    "        \"n_fail\": 0,\n",
    "        \n",
    "        \"n_format_fail\": 0,\n",
    "        \"n_logic_fail\": 0,\n",
    "\n",
    "        \"ticket_count_parse_error\": 0,\n",
    "        \"ticket_lines_format_error\": 0,\n",
    "        \"result_labels_parse_error\": 0,\n",
    "        \"ticket_count_mismatch\": 0,\n",
    "        \"ticket_numbers_invalid\": 0,\n",
    "\n",
    "        \"match_stats_mismatch\": 0,\n",
    "        \"roi_mismatch\": 0,\n",
    "\n",
    "        \"test_fail\": 0,  # 형식은 통과했는데 match_check/roi_ok에서 깨진 경우\n",
    "    }\n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "        if max_samples is not None and i >= max_samples:\n",
    "            break\n",
    "\n",
    "        prompt = get_prompt_for_testset(block)\n",
    "        get_text = generate_text(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            device=device,\n",
    "        )\n",
    "        res = test_one_sample(prompt, get_text)\n",
    "\n",
    "        stats[\"n_total\"] += 1\n",
    "\n",
    "        if res.get(\"ok\"):\n",
    "            stats[\"n_ok\"] += 1\n",
    "            continue\n",
    "\n",
    "        # 실패\n",
    "        stats[\"n_fail\"] += 1\n",
    "\n",
    "        err = res.get(\"errors\")\n",
    "        # print(err)\n",
    "        if not res.get(\"format_ok\"):\n",
    "            stats[\"n_format_fail\"] += 1\n",
    "            if \"ticket_count_parse_error\" in err:\n",
    "                stats[\"ticket_count_parse_error\"] += 1\n",
    "            elif \"ticket_lines_format_error\" in err:\n",
    "                stats[\"ticket_lines_format_error\"] += 1\n",
    "            elif \"result_labels_parse_error\" in err:\n",
    "                stats[\"result_labels_parse_error\"] += 1\n",
    "            elif \"ticket_count_mismatch\" in err:\n",
    "                stats[\"ticket_count_mismatch\"] += 1\n",
    "            elif \"ticket_numbers_invalid\" in err:\n",
    "                stats[\"ticket_numbers_invalid\"] += 1\n",
    "        \n",
    "        if not res.get(\"logic_ok\"):\n",
    "            stats[\"n_logic_fail\"] += 1\n",
    "            if \"match_stats_mismatch\" in err:\n",
    "                stats[\"match_stats_mismatch\"] += 1\n",
    "            if \"roi_mismatch\" in err:\n",
    "                stats[\"roi_mismatch\"] += 1\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0d076164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SUMMARY ===\n",
      "n_total : 5\n",
      "n_ok : 2\n",
      "n_fail : 3\n",
      "n_format_fail : 0\n",
      "n_logic_fail : 3\n",
      "ticket_count_parse_error : 0\n",
      "ticket_lines_format_error : 0\n",
      "result_labels_parse_error : 0\n",
      "ticket_count_mismatch : 0\n",
      "ticket_numbers_invalid : 0\n",
      "match_stats_mismatch : 3\n",
      "roi_mismatch : 1\n",
      "test_fail : 0\n"
     ]
    }
   ],
   "source": [
    "summary = evaluate_testset(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    test_path=\"lotto_test.txt\",\n",
    "    device=device,\n",
    "    max_samples=5,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "print(\"=== TEST SUMMARY ===\")\n",
    "for k, v in summary.items():\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d4b6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea70505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_tickets_from_generated(text: str):\n",
    "    \"\"\"\n",
    "    LLM 출력에서 구매번호 리스트 파싱\n",
    "    예:\n",
    "    [1,3,7,9,21,22]\n",
    "    [3,8,11,15,22,35]\n",
    "    ...\n",
    "    \"\"\"\n",
    "    tickets = []\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"[\") and line.endswith(\"]\"):\n",
    "            try:\n",
    "                nums = re.findall(r\"\\d+\", line)\n",
    "                nums = list(map(int, nums))\n",
    "                tickets.append(nums)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    return tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3be4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_labels_from_block(text: str):\n",
    "    \"\"\"\n",
    "    텍스트(데이터셋/LLM 출력 공통)에서\n",
    "    3개일치~6개일치, 수익률(%)을 파싱.\n",
    "    없거나 숫자 변환 실패 시 None.\n",
    "    \"\"\"\n",
    "    m3  = re.search(r\"3개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", text)\n",
    "    m4  = re.search(r\"4개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", text)\n",
    "    m5  = re.search(r\"5개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", text)\n",
    "    m5b = re.search(r\"5개보너스일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", text)\n",
    "    m6  = re.search(r\"6개일치\\s*\\([^)]*\\)\\s*=\\s*(-?\\d+)\", text)\n",
    "    mroi = re.search(r\"수익률\\s*=?\\s*([-+]?\\d+(?:\\.\\d+)?)\\s*%\", text)\n",
    "\n",
    "    if not all([m3, m4, m5, m5b, m6, mroi]):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return {\n",
    "            \"m3\":  int(m3.group(1)),\n",
    "            \"m4\":  int(m4.group(1)),\n",
    "            \"m5\":  int(m5.group(1)),\n",
    "            \"m5b\": int(m5b.group(1)),\n",
    "            \"m6\":  int(m6.group(1)),\n",
    "            \"roi\": float(mroi.group(1)),   # 예: 125.0\n",
    "        }\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3fd9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_money_from_block(block: str) -> int:\n",
    "    m = re.search(r\"money\\s*=\\s*(\\d+)\", block)\n",
    "    if not m:\n",
    "        return 0\n",
    "    return int(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58922c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(ticket, winning, bonus):\n",
    "    \"\"\"\n",
    "    ticket: [6개 숫자]\n",
    "    winning: set([...])\n",
    "    bonus: int\n",
    "    \"\"\"\n",
    "    match_cnt = len(set(ticket) & winning)\n",
    "    bonus_match = bonus in ticket\n",
    "    return match_cnt, bonus_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fff7f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roi(stat, money:int):\n",
    "    \"\"\"\n",
    "    stat: simulate_lotto 결과 dict\n",
    "    \"\"\"\n",
    "\n",
    "    reward_table = {\n",
    "        \"m3\": 5000,\n",
    "        \"m4\": 50000,\n",
    "        \"m5\": 1500000,\n",
    "        \"m5b\": 30000000,\n",
    "        \"m6\": 2000000000,\n",
    "    }\n",
    "\n",
    "    total_reward = 0\n",
    "    for k, v in stat.items():\n",
    "        total_reward += reward_table[k] * v\n",
    "\n",
    "    if money <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    roi = total_reward / money * 100.0\n",
    "    return roi\n",
    "\n",
    "\n",
    "def stat_values(stat):\n",
    "    return [stat[k] for k in [\"m3\", \"m4\", \"m5\", \"m5b\", \"m6\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28e42531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lotto(tickets, winning_numbers, bonus):\n",
    "    \"\"\"\n",
    "    tickets: [[6개], [6개], ...]\n",
    "    \"\"\"\n",
    "\n",
    "    win_set = set(winning_numbers)\n",
    "\n",
    "    result = {\n",
    "        \"m3\": 0,\n",
    "        \"m4\": 0,\n",
    "        \"m5\": 0,\n",
    "        \"m5b\": 0,\n",
    "        \"m6\": 0\n",
    "    }\n",
    "\n",
    "    for t in tickets:\n",
    "        match_cnt, bonus_match = count_matches(t, win_set, bonus)\n",
    "\n",
    "        if match_cnt == 3:\n",
    "            result[\"m3\"] += 1\n",
    "        elif match_cnt == 4:\n",
    "            result[\"m4\"] += 1\n",
    "        elif match_cnt == 5 and bonus_match:\n",
    "            result[\"m5b\"] += 1\n",
    "        elif match_cnt == 5:\n",
    "            result[\"m5\"] += 1\n",
    "        elif match_cnt == 6:\n",
    "            result[\"m6\"] += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49775be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functional_test_one_sample(gen_text, gt_block):\n",
    "    \"\"\"\n",
    "    gen_text: LLM이 출력한 전체 텍스트\n",
    "    gt_block: 데이터셋 원본 블록 (정답 포함)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 정답 파싱\n",
    "    gt = parse_labels_from_block(gt_block)\n",
    "    if gt is None:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"reason\": \"no_gt\"\n",
    "        }\n",
    "\n",
    "    # 2. LLM 출력에서 구매번호 파싱\n",
    "    pred_tickets = parse_tickets_from_generated(gen_text)\n",
    "\n",
    "    if not pred_tickets:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"reason\": \"ticket_parse_fail\"\n",
    "        }\n",
    "\n",
    "    # 3. winning / bonus 파싱\n",
    "    winning = re.search(r\"winning=([0-9,]+)\", gt_block)\n",
    "    bonus = re.search(r\"bonus=(\\d+)\", gt_block)\n",
    "    money = parse_money_from_block(gt_block)\n",
    "\n",
    "    if not winning or not bonus:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"reason\": \"cannot_parse_winning\"\n",
    "        }\n",
    "\n",
    "    winning_nums = list(map(int, winning.group(1).split(\",\")))\n",
    "    bonus_num = int(bonus.group(1))\n",
    "\n",
    "    # 4. 실제 시뮬레이션\n",
    "    sim_stat = simulate_lotto(pred_tickets, winning_nums, bonus_num)\n",
    "\n",
    "    # 5. 데이터셋 기준 ROI 계산\n",
    "    sim_roi = calculate_roi(sim_stat, money)\n",
    "\n",
    "    # 6. 정확도 비교\n",
    "    acc = {\n",
    "        \"m3_match\": sim_stat[\"m3\"] == gt[\"m3\"],\n",
    "        \"m4_match\": sim_stat[\"m4\"] == gt[\"m4\"],\n",
    "        \"m5_match\": sim_stat[\"m5\"] == gt[\"m5\"],\n",
    "        \"m5b_match\": sim_stat[\"m5b\"] == gt[\"m5b\"],\n",
    "        \"m6_match\": sim_stat[\"m6\"] == gt[\"m6\"],\n",
    "        \"roi_diff\": sim_roi == gt[\"roi\"],\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"ok\": True,\n",
    "        \"simulated\": sim_stat,\n",
    "        \"simulated_roi\": sim_roi,\n",
    "        \"gt\": gt,\n",
    "        \"acc\": acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b120ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_functional_tests(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    test_path: str = \"lotto_test.txt\",\n",
    "    device: str = \"cpu\",\n",
    "    max_samples: int = 100,\n",
    "    max_new_tokens: int = 256,\n",
    "):\n",
    "    \"\"\"\n",
    "    functional_test_one_sample(gen_text, gt_block)를 이용해서\n",
    "    데이터셋 전체를 테스트한다.\n",
    "    \"\"\"\n",
    "\n",
    "    blocks = load_blocks(test_path)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    total = 0\n",
    "    ok_count = 0\n",
    "    fail_count = 0\n",
    "    ticket_parse_fail = 0\n",
    "    winning_parse_fail = 0\n",
    "\n",
    "    # 정확도 누적\n",
    "    hit_match_counts = {\n",
    "        \"m3\": 0,\n",
    "        \"m4\": 0,\n",
    "        \"m5\": 0,\n",
    "        \"m5b\": 0,\n",
    "        \"m6\": 0,\n",
    "    }\n",
    "    hit_eval_counts = {\n",
    "        \"m3\": 0,\n",
    "        \"m4\": 0,\n",
    "        \"m5\": 0,\n",
    "        \"m5b\": 0,\n",
    "        \"m6\": 0,\n",
    "    }\n",
    "\n",
    "    roi_abs_error_sum = 0.0\n",
    "    roi_eval_count = 0\n",
    "\n",
    "    for i, blk in enumerate(blocks):\n",
    "        if i >= max_samples:\n",
    "            break\n",
    "\n",
    "        # --- 1) 프롬프트 생성 ---\n",
    "        prompt = make_prompt_for_tickets(blk)\n",
    "\n",
    "        # --- 2) LLM 호출 ---\n",
    "        gen_text = generate_text(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt,\n",
    "            device=device,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "\n",
    "        # --- 3) 핵심 테스트 함수 호출 ---\n",
    "        r = functional_test_one_sample(gen_text, blk)\n",
    "\n",
    "        total += 1\n",
    "        results.append(r)\n",
    "\n",
    "        if not r[\"ok\"]:\n",
    "            fail_count += 1\n",
    "            if r[\"reason\"] == \"ticket_parse_fail\":\n",
    "                ticket_parse_fail += 1\n",
    "            elif r[\"reason\"] == \"cannot_parse_winning\":\n",
    "                winning_parse_fail += 1\n",
    "            continue\n",
    "\n",
    "        ok_count += 1\n",
    "\n",
    "        # --- 4) 정확도 누적 ---\n",
    "        acc = r[\"acc\"]\n",
    "\n",
    "        if \"m3_match\" in acc:\n",
    "            hit_eval_counts[\"m3\"] += 1\n",
    "            if acc[\"m3_match\"]:\n",
    "                hit_match_counts[\"m3\"] += 1\n",
    "\n",
    "        if \"m4_match\" in acc:\n",
    "            hit_eval_counts[\"m4\"] += 1\n",
    "            if acc[\"m4_match\"]:\n",
    "                hit_match_counts[\"m4\"] += 1\n",
    "\n",
    "        if \"m5_match\" in acc:\n",
    "            hit_eval_counts[\"m5\"] += 1\n",
    "            if acc[\"m5_match\"]:\n",
    "                hit_match_counts[\"m5\"] += 1\n",
    "\n",
    "        if \"m5b_match\" in acc:\n",
    "            hit_eval_counts[\"m5b\"] += 1\n",
    "            if acc[\"m5b_match\"]:\n",
    "                hit_match_counts[\"m5b\"] += 1\n",
    "\n",
    "        if \"m6_match\" in acc:\n",
    "            hit_eval_counts[\"m6\"] += 1\n",
    "            if acc[\"m6_match\"]:\n",
    "                hit_match_counts[\"m6\"] += 1\n",
    "\n",
    "        # ROI 오차 누적\n",
    "        if \"roi_diff\" in acc:\n",
    "            roi_abs_error_sum += acc[\"roi_diff\"]\n",
    "            roi_eval_count += 1\n",
    "\n",
    "    # --- 5) 최종 Summary 계산 ---\n",
    "    if total == 0:\n",
    "        return {\n",
    "            \"n_eval\": 0\n",
    "        }\n",
    "\n",
    "    parse_success_ratio = ok_count / total\n",
    "\n",
    "    acc_hit = {}\n",
    "    for k in hit_match_counts.keys():\n",
    "        cnt = hit_eval_counts[k] if hit_eval_counts[k] > 0 else 1\n",
    "        acc_hit[k] = hit_match_counts[k] / cnt\n",
    "\n",
    "    if roi_eval_count > 0:\n",
    "        roi_mae = roi_abs_error_sum / roi_eval_count\n",
    "    else:\n",
    "        roi_mae = 0.0\n",
    "\n",
    "    summary = {\n",
    "        \"n_eval\": total,\n",
    "        \"success_ratio\": parse_success_ratio,\n",
    "        \"fail_cnt\": fail_count,\n",
    "        \"fail_ticket_parse\": ticket_parse_fail,\n",
    "        \"fail_winning_parse\": winning_parse_fail,\n",
    "        \"acc_hit\": acc_hit,     # m3~m6 정확도\n",
    "        \"roi_mae\": roi_mae      # 수익률 평균 오차\n",
    "    }\n",
    "\n",
    "    return summary, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45d2a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "checkpoint loaded from: lotto_gpt_best.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "# 체크포인트 로드 (파일 이름 맞게 수정 가능)\n",
    "ckpt_path = \"lotto_gpt_best.pt\"   # 또는 \"lotto_gpt_epoch030.pt\" 등\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "print(\"checkpoint loaded from:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "692316e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SUMMARY ===\n",
      "n_eval : 100\n",
      "success_ratio : 1.0\n",
      "fail_cnt : 0\n",
      "fail_ticket_parse : 0\n",
      "fail_winning_parse : 0\n",
      "acc_hit : {'m3': 0.64, 'm4': 0.88, 'm5': 0.93, 'm5b': 1.0, 'm6': 0.97}\n",
      "roi_mae : 0.37\n"
     ]
    }
   ],
   "source": [
    "summary, results = run_functional_tests(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    test_path=\"lotto_test.txt\",\n",
    "    device=device,\n",
    "    max_samples=100,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "print(\"=== TEST SUMMARY ===\")\n",
    "for k, v in summary.items():\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46bc140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'simulated': {'m3': 0, 'm4': 0, 'm5': 0, 'm5b': 0, 'm6': 0}, 'simulated_roi': 0.0, 'gt': {'m3': 0, 'm4': 0, 'm5': 1, 'm5b': 0, 'm6': 0, 'roi': 21428.6}, 'acc': {'m3_match': True, 'm4_match': True, 'm5_match': False, 'm5b_match': True, 'm6_match': True, 'roi_diff': False}}\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627b85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
