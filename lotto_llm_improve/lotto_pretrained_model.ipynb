{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1035248d",
   "metadata": {},
   "source": [
    "# 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bd9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수 : 72\n",
      "토큰수 : 15\n",
      "[220, 543, 5850, 7342, 6129, 1088, 262, 2119, 24433, 339, 991, 550, 465, 1336, 82]\n",
      "  which Harry watched fly around the room wishing he still had his fulls\n",
      "220 :  \n",
      "543 :  which\n",
      "5850 :  Harry\n",
      "7342 :  watched\n",
      "6129 :  fly\n",
      "1088 :  around\n",
      "262 :  the\n",
      "2119 :  room\n",
      "24433 :  wishing\n",
      "339 :  he\n",
      "991 :  still\n",
      "550 :  had\n",
      "465 :  his\n",
      "1336 :  full\n",
      "82 : s\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"  which Harry watched fly around the room wishing he still had his fulls\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수 :\", len(text))  # 글자수: 26\n",
    "print(\"토큰수 :\", len(tokens))  # 토큰수: 6\n",
    "print(tokens)  # [15496, 2159, 257, 281, 3453, 13]\n",
    "print(tokenizer.decode(tokens))  # Harry Potter was a wizard.\n",
    "for token in tokens:\n",
    "    print(token, \":\", tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e8c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\github\\llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n",
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. GPT-2 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 2. GPT-2는 기본 pad_token이 없어서 직접 설정\n",
    "# if tokenizer.pad_token is None:\n",
    "#     special_tokens_dict = {'pad_token': '<|pad|>'}\n",
    "#     num_added = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# pad를 따로 추가하지 말고, eos를 그대로 pad로 사용\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pad_id = tokenizer.pad_token_id  # == eos_id\n",
    "\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d61185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 150000\n",
      "원본 샘플:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나 넣어놨으니까 \"\\n\\n\" 기준으로 자름\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"샘플 개수:\", len(train_samples))\n",
    "\n",
    "example = train_samples[0]\n",
    "print(\"원본 샘플:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e9b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 512])\n",
      "attention_mask shape: torch.Size([1, 512])\n",
      "디코딩된 텍스트:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "max_len = 512  # 임시\n",
    "\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=max_len,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",  # PyTorch 텐서로\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"]        # shape: (1, max_len)\n",
    "attention_mask = enc[\"attention_mask\"]  # shape: (1, max_len)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# 디코딩해서 잘 복원되는지 확인\n",
    "decoded = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "print(\"디코딩된 텍스트:\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1432b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class LottoDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len: int, focus_len: int = 118):\n",
    "        \"\"\"\n",
    "        focus_len: 시퀀스 뒤에서부터 몇 개 토큰을\n",
    "                   '결과/수익률 구간'이라고 보고 가중치를 줄지\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.eos = tokenizer.eos_token\n",
    "        self.focus_len = focus_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_txt = self.texts[idx]\n",
    "\n",
    "        txt = row_txt + self.eos\n",
    "\n",
    "        # max_len+1 길이로 토큰화 → x:[:-1], y:[1:] 사용\n",
    "        enc = self.tokenizer(\n",
    "            txt,\n",
    "            max_length=self.max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn_mask = enc[\"attention_mask\"][0]  # (max_len+1,)\n",
    "\n",
    "        # 언어모델용 input/target\n",
    "        x = ids[:-1].clone()       # (max_len,)\n",
    "        y = ids[1:].clone()        # (max_len,)\n",
    "        x_mask = attn_mask[:-1].clone()\n",
    "\n",
    "        # pad 위치는 loss에서 무시되도록 -100\n",
    "        y[x_mask == 0] = -100\n",
    "\n",
    "        # ----- roi_mask 생성 (결과/수익률 구간) -----\n",
    "        # 실제 토큰 길이 (pad 제외)\n",
    "        valid_len = int(x_mask.sum().item())   # 예: 380 토큰\n",
    "        roi_mask = torch.zeros_like(x_mask)    # (max_len,)\n",
    "\n",
    "        # 뒤에서 focus_len개를 결과 구간으로 설정\n",
    "        start = max(0, valid_len - self.focus_len)\n",
    "        roi_mask[start:valid_len] = 1\n",
    "\n",
    "        return x, y, x_mask, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e2f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([512])\n",
      "y shape: torch.Size([512])\n",
      "x_mask shape: torch.Size([512])\n",
      "roi_mask shape: torch.Size([512])\n",
      "x[:20]: tensor([26316,    28, 27559,   198, 14463,    28,    16,    11,  1157,    11,\n",
      "         1314,    11,  1507,    11,  1959,    11,  2548,   198,  4189,   385])\n",
      "y[:20]: tensor([   28, 27559,   198, 14463,    28,    16,    11,  1157,    11,  1314,\n",
      "           11,  1507,    11,  1959,    11,  2548,   198,  4189,   385,    28])\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "train_ds = LottoDataset(train_samples, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "x, y, x_mask, roi_mask = train_ds[0]\n",
    "\n",
    "print(\"x shape:\", x.shape)          # torch.Size([256])\n",
    "print(\"y shape:\", y.shape)          # torch.Size([256])\n",
    "print(\"x_mask shape:\", x_mask.shape)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)\n",
    "\n",
    "print(\"x[:20]:\", x[:20])\n",
    "print(\"y[:20]:\", y[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f8c7",
   "metadata": {},
   "source": [
    "DataSet 출력값 예시\n",
    "\n",
    "X TEXT:\n",
    "money=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "\n",
    "Y TEXT:\n",
    "oney=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a468413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|>\n",
      "pad_token_id: 50256\n",
      "vocab_size: 50257\n",
      "\n",
      "input_ids shape: torch.Size([512])\n",
      "attention_mask shape: torch.Size([512])\n",
      "\n",
      "=== DECODED TEXT ===\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "\n",
    "\n",
    "# lotto_train.txt 읽기\n",
    "def load_text_samples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "\n",
    "# 샘플 하나\n",
    "example = train_samples[0]\n",
    "# print(\"=== ORIGINAL TEXT ===\")\n",
    "# print(example)\n",
    "\n",
    "# encode\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"][0]\n",
    "attention_mask = enc[\"attention_mask\"][0]\n",
    "\n",
    "print(\"\\ninput_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# decode\n",
    "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== DECODED TEXT ===\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4947dc",
   "metadata": {},
   "source": [
    "# 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ae71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 샘플 수: 150000\n",
      "첫 샘플 원본:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나씩 있다고 가정 → \"\\n\\n\" 기준 split\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"train 샘플 수:\", len(train_texts))\n",
    "print(\"첫 샘플 원본:\")\n",
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8db334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([4, 512])\n",
      "y_batch shape: torch.Size([4, 512])\n",
      "mask_batch shape: torch.Size([4, 512])\n",
      "roi_mask shape: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 512  # 일단 256 정도로 가정\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 배치 하나만 꺼내서 확인해보자\n",
    "x_batch, y_batch, mask_batch, roi_mask = next(iter(train_loader))\n",
    "\n",
    "print(\"x_batch shape:\", x_batch.shape)        # (B, T) = (4, 256)\n",
    "print(\"y_batch shape:\", y_batch.shape)        # (4, 256)\n",
    "print(\"mask_batch shape:\", mask_batch.shape)  # (4, 256)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)      # (4, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fabdab",
   "metadata": {},
   "source": [
    "### focus_len 마지막 증가할 가중치 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e711222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_focus_len(texts, tokenizer, max_len: int, \n",
    "                       target_tokens=(\"3개일치\", \"수익률\"),\n",
    "                       sample_size: int = 1000,\n",
    "                       quantile: float = 0.95):\n",
    "    \"\"\"\n",
    "    texts: lotto_train.txt에서 읽어온 전체 텍스트 리스트\n",
    "    target_tokens: 결과/수익률 블록을 대표하는 토큰 문자열들\n",
    "    sample_size: 몇 개 샘플만 뽑아서 통계 낼지\n",
    "    quantile: 상위 몇 %까지 커버할지 (0.95면 95퍼센타일)\n",
    "    \"\"\"\n",
    "    n = min(len(texts), sample_size)\n",
    "    lengths = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row_txt = texts[i]\n",
    "        txt = row_txt + tokenizer.eos_token\n",
    "\n",
    "        enc = tokenizer(\n",
    "            txt,\n",
    "            max_length=max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn = enc[\"attention_mask\"][0]     # (max_len+1,)\n",
    "\n",
    "        valid_len = int(attn.sum().item())\n",
    "        ids_list = ids[:valid_len].tolist()\n",
    "\n",
    "        # 이 샘플에서 결과 블록 시작 위치를 찾는다\n",
    "        start_idx = valid_len  # 기본값: 못 찾으면 tail=0\n",
    "\n",
    "        for tok_str in target_tokens:\n",
    "            pat = tokenizer(tok_str, add_special_tokens=False)[\"input_ids\"]\n",
    "            L = len(pat)\n",
    "\n",
    "            for j in range(valid_len - L + 1):\n",
    "                if ids_list[j:j+L] == pat:\n",
    "                    start_idx = min(start_idx, j)\n",
    "                    break  # 이 토큰은 찾았으니 다음 토큰으로\n",
    "\n",
    "        tail_len = valid_len - start_idx\n",
    "        if tail_len < 0:\n",
    "            tail_len = 0\n",
    "\n",
    "        lengths.append(tail_len)\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "    print(\"샘플 개수:\", len(lengths))\n",
    "    print(\"min tail_len:\", lengths.min())\n",
    "    print(\"avg tail_len:\", lengths.mean())\n",
    "    print(\"max tail_len:\", lengths.max())\n",
    "    focus_len = int(np.quantile(lengths, quantile))\n",
    "    print(f\"{int(quantile*100)} 퍼센타일 tail_len:\", focus_len)\n",
    "\n",
    "    return focus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fee5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 1000\n",
      "min tail_len: 117\n",
      "avg tail_len: 117.176\n",
      "max tail_len: 120\n",
      "95 퍼센타일 tail_len: 118\n",
      "최종 선택된 focus_len = 118\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")\n",
    "\n",
    "focus_len = estimate_focus_len(\n",
    "    train_texts,\n",
    "    tokenizer,\n",
    "    max_len=max_len,\n",
    "    target_tokens=(\"3개일치\", \"수익률\"),\n",
    "    sample_size=1000,\n",
    "    quantile=0.95,\n",
    ")\n",
    "print(\"최종 선택된 focus_len =\", focus_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818c09",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43da2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class GPTConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        n_layer: int = 4,\n",
    "        n_head: int = 4,\n",
    "        d_model: int = 256,\n",
    "        d_ff: int = 1024,\n",
    "        max_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.max_len = max_len\n",
    "        self.dropout = dropout\n",
    "        self.pad_id = pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.d_model = config.d_model\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.qkv = nn.Linear(config.d_model, 3 * config.d_model)\n",
    "        self.proj = nn.Linear(config.d_model, config.d_model)\n",
    "\n",
    "        mask = torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\",\n",
    "            mask.view(1, 1, config.max_len, config.max_len)\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        head_dim = C // H\n",
    "\n",
    "        qkv = self.qkv(x)              # (B, T, 3C)\n",
    "        q, k, v = qkv.split(C, dim=2)  # (B, T, C) each\n",
    "\n",
    "        q = q.view(B, T, H, head_dim).transpose(1, 2)  # (B, H, T, head_dim)\n",
    "        k = k.view(B, T, H, head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, H, head_dim).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / (head_dim ** 0.5)  # (B, H, T, T)\n",
    "\n",
    "        causal_mask = self.causal_mask[:, :, :T, :T]\n",
    "        att = att.masked_fill(causal_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: (B, T) → (B, 1, 1, T)\n",
    "            pad_mask = attn_mask.view(B, 1, 1, T)\n",
    "            att = att.masked_fill(pad_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "\n",
    "        y = att @ v                    # (B, H, T, head_dim)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fea54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.d_ff, config.d_model),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = x + self.attn(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fea343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        self.pos_emb = nn.Embedding(config.max_len, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(config.n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        self.head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "\n",
    "        # (선택) 입력 임베딩과 출력 head weight tying\n",
    "        self.head.weight = self.tok_emb.weight\n",
    "\n",
    "    def forward(self, idx, attn_mask=None):\n",
    "        # idx: (B, T)\n",
    "        B, T = idx.size()\n",
    "        device = idx.device\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device)\n",
    "        pos = pos.unsqueeze(0).expand(B, T)  # (B, T)\n",
    "\n",
    "        x = self.tok_emb(idx) + self.pos_emb(pos)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b44d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, tokenizer, prompt: str, max_new_tokens: int = 200, device=\"cpu\"):\n",
    "    \n",
    "    model.eval()\n",
    "    max_len = model.config.max_len\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # 1) 처음에는 패딩 없이 실제 길이만큼만 인코딩\n",
    "    enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    x = enc[\"input_ids\"].to(device)      # (1, T0)\n",
    "    attn_mask = enc[\"attention_mask\"].to(device)  # (1, T0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 2) 모델에 넣기 전에 길이가 max_len을 넘으면 뒤에서 max_len만 유지\n",
    "        if x.size(1) > max_len:\n",
    "            x = x[:, -max_len:]\n",
    "            attn_mask = attn_mask[:, -max_len:]\n",
    "\n",
    "        # 3) forward\n",
    "        logits = model(x, attn_mask=attn_mask)        # (1, T, vocab)\n",
    "        last_logits = logits[:, -1, :]                # (1, vocab)\n",
    "\n",
    "        probs = torch.softmax(last_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "        next_token = next_id.item()\n",
    "\n",
    "        if next_token == eos_token_id:\n",
    "            break\n",
    "\n",
    "        # 4) 새 토큰 이어붙이기\n",
    "        x = torch.cat([x, next_id], dim=1)  # (1, T+1)\n",
    "        next_mask = torch.ones_like(next_id, device=device)\n",
    "        attn_mask = torch.cat([attn_mask, next_mask], dim=1)\n",
    "\n",
    "    # 5) 결과 디코딩\n",
    "    out_ids = x[0].tolist()\n",
    "    text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de740e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "train samples: 150000\n",
      "val samples: 15000\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 2) 데이터 로딩\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")  # 없다면 주석 처리하고 train만 써도 됨\n",
    "\n",
    "print(\"train samples:\", len(train_texts))\n",
    "print(\"val samples:\", len(val_texts))\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "val_ds = LottoDataset(val_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "# 3) 모델 & optimizer & loss\n",
    "config = GPTConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    d_model=256,\n",
    "    d_ff=1024,\n",
    "    max_len=max_len,\n",
    "    dropout=0.1,\n",
    "    pad_id=pad_id,\n",
    ")\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81b8fe",
   "metadata": {},
   "source": [
    "# Eos 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e978db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9653984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n",
      "\n",
      "DATASET 내부 tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL tokenizer:\")\n",
    "print(\"  pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)\n",
    "\n",
    "print(\"\\nDATASET 내부 tokenizer:\")\n",
    "print(\"  pad_token:\", train_ds.tokenizer.pad_token, \"id:\", train_ds.tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", train_ds.tokenizer.eos_token, \"id:\", train_ds.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab8a79",
   "metadata": {},
   "source": [
    "#학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9223e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=0.9341, val_loss=0.6675\n",
      "[Epoch 002] train_loss=0.2726, val_loss=0.6155\n",
      "[Epoch 003] train_loss=0.2577, val_loss=0.6098\n",
      "[Epoch 004] train_loss=0.2542, val_loss=0.6087\n",
      "[Epoch 005] train_loss=0.2527, val_loss=0.6075\n",
      "[Epoch 006] train_loss=0.2518, val_loss=0.6069\n",
      "[Epoch 007] train_loss=0.2512, val_loss=0.6058\n",
      "[Epoch 008] train_loss=0.2507, val_loss=0.6058\n",
      "[Epoch 009] train_loss=0.2504, val_loss=0.6056\n",
      "[Epoch 010] train_loss=0.2502, val_loss=0.6055\n",
      "[Epoch 011] train_loss=0.2500, val_loss=0.6049\n",
      "[Epoch 012] train_loss=0.2498, val_loss=0.6052\n",
      "[Epoch 013] train_loss=0.2497, val_loss=0.6050\n",
      "[Epoch 014] train_loss=0.2496, val_loss=0.6049\n",
      "[Epoch 015] train_loss=0.2496, val_loss=0.6047\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "pad_target_id = -100        # y에서 pad 자리에 들어있는 값\n",
    "alpha = 5.0                 # 결과/수익률 구간 가중치 배율\n",
    "epochs = 15\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "accum_steps = 4  # 그대로 (batch 8 * 4 = effective 32)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # ----- Train -----\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (x, y, mask, roi) in enumerate(train_loader, start=1):\n",
    "        x    = x.to(device)       # (B, T)\n",
    "        y    = y.to(device)       # (B, T)  pad는 -100\n",
    "        mask = mask.to(device)    # (B, T)\n",
    "        roi  = roi.to(device)     # (B, T)\n",
    "\n",
    "        logits = model(x, attn_mask=mask)   # (B, T, vocab)\n",
    "        B, T, V = logits.size()\n",
    "\n",
    "        # 1) 펼치기\n",
    "        logits_flat = logits.view(-1, V)    # (B*T, V)\n",
    "        y_flat      = y.view(-1)           # (B*T,)\n",
    "        roi_flat    = roi.view(-1).float() # (B*T,)\n",
    "\n",
    "        # 2) 토큰별 CE loss (pad는 ignore_index=-100)\n",
    "        per_token_loss = F.cross_entropy(\n",
    "            logits_flat,\n",
    "            y_flat,\n",
    "            reduction=\"none\",\n",
    "            ignore_index=pad_target_id,\n",
    "        )  # (B*T,)\n",
    "\n",
    "        # 3) pad 아닌 위치 마스크\n",
    "        non_pad_mask = (y_flat != pad_target_id).float()  # pad면 0, 나머지 1\n",
    "\n",
    "        # roi가 pad 위치를 건드리지 않도록 한 번 더 마스킹\n",
    "        roi_flat = roi_flat * non_pad_mask\n",
    "\n",
    "        # 4) 가중치: 기본 1, roi 구간은 alpha배\n",
    "        base_w  = non_pad_mask                  # pad: 0, 나머지: 1\n",
    "        weights = base_w + roi_flat * (alpha - 1.0)\n",
    "        # -> roi_flat=1이면 1+(α-1)=α, roi_flat=0이면 1\n",
    "\n",
    "        # 5) 최종 loss: 가중 평균\n",
    "        loss = (per_token_loss * weights).sum() / (weights.sum() + 1e-8)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # gradient accumulation\n",
    "        loss = loss / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if step % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    else:\n",
    "        # 마지막에 accum_steps로 딱 안 나누어떨어지는 경우 방어 코드\n",
    "        if (step % accum_steps) != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ----- Validation (여기는 가중치 없이, pad만 무시) -----\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, mask, roi in val_loader:\n",
    "            x    = x.to(device)\n",
    "            y    = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            logits = model(x, attn_mask=mask)\n",
    "            B, T, V = logits.size()\n",
    "\n",
    "            logits_flat = logits.view(-1, V)\n",
    "            y_flat      = y.view(-1)\n",
    "\n",
    "            per_token_loss = F.cross_entropy(\n",
    "                logits_flat,\n",
    "                y_flat,\n",
    "                reduction=\"none\",\n",
    "                ignore_index=pad_target_id,\n",
    "            )\n",
    "\n",
    "            non_pad_mask = (y_flat != pad_target_id).float()\n",
    "            val_loss = (per_token_loss * non_pad_mask).sum() / (non_pad_mask.sum() + 1e-8)\n",
    "            val_loss_sum += val_loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {epoch:03d}] train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # ----- 체크포인트 -----\n",
    "    torch.save(model.state_dict(), f\"lotto_gpt_epoch{epoch:03d}.pt\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"lotto_gpt_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4f961da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"train_loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87d375b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 65])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=5000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=5\n",
      "구매번호:\n",
      "[1,2,3,4,5,6]\n",
      "[11,13,19,25,30,45]\n",
      "[15,22,23,36,37,40]\n",
      "[8,25,35,37,39,40]\n",
      "[11,14,25,28,44,45]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=5000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    "    \"티켓수=5\\n\"\n",
    "    \"구매번호:\\n\"\n",
    "    \"[1,2,3,4,5,6]\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "219f7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "checkpoint loaded from: lotto_gpt_best.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "# 체크포인트 로드 (파일 이름 맞게 수정 가능)\n",
    "ckpt_path = \"lotto_gpt_best.pt\"   # 또는 \"lotto_gpt_epoch030.pt\" 등\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "print(\"checkpoint loaded from:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1ba4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 25])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=1000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=1\n",
      "구매번호:\n",
      "[4,17,20,31,32,36]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 1\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=5000.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=1000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
