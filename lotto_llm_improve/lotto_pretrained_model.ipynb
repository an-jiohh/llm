{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1035248d",
   "metadata": {},
   "source": [
    "# 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bd9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수 : 72\n",
      "토큰수 : 15\n",
      "[220, 543, 5850, 7342, 6129, 1088, 262, 2119, 24433, 339, 991, 550, 465, 1336, 82]\n",
      "  which Harry watched fly around the room wishing he still had his fulls\n",
      "220 :  \n",
      "543 :  which\n",
      "5850 :  Harry\n",
      "7342 :  watched\n",
      "6129 :  fly\n",
      "1088 :  around\n",
      "262 :  the\n",
      "2119 :  room\n",
      "24433 :  wishing\n",
      "339 :  he\n",
      "991 :  still\n",
      "550 :  had\n",
      "465 :  his\n",
      "1336 :  full\n",
      "82 : s\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"  which Harry watched fly around the room wishing he still had his fulls\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수 :\", len(text))  # 글자수: 26\n",
    "print(\"토큰수 :\", len(tokens))  # 토큰수: 6\n",
    "print(tokens)  # [15496, 2159, 257, 281, 3453, 13]\n",
    "print(tokenizer.decode(tokens))  # Harry Potter was a wizard.\n",
    "for token in tokens:\n",
    "    print(token, \":\", tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e8c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\github\\llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n",
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. GPT-2 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 2. GPT-2는 기본 pad_token이 없어서 직접 설정\n",
    "# if tokenizer.pad_token is None:\n",
    "#     special_tokens_dict = {'pad_token': '<|pad|>'}\n",
    "#     num_added = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# pad를 따로 추가하지 말고, eos를 그대로 pad로 사용\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pad_id = tokenizer.pad_token_id  # == eos_id\n",
    "\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d61185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 50000\n",
      "원본 샘플:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나 넣어놨으니까 \"\\n\\n\" 기준으로 자름\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"샘플 개수:\", len(train_samples))\n",
    "\n",
    "example = train_samples[0]\n",
    "print(\"원본 샘플:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e9b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 512])\n",
      "attention_mask shape: torch.Size([1, 512])\n",
      "디코딩된 텍스트:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "max_len = 512  # 임시\n",
    "\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=max_len,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",  # PyTorch 텐서로\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"]        # shape: (1, max_len)\n",
    "attention_mask = enc[\"attention_mask\"]  # shape: (1, max_len)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# 디코딩해서 잘 복원되는지 확인\n",
    "decoded = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "print(\"디코딩된 텍스트:\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1432b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class LottoDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len: int, focus_len: int = 118):\n",
    "        \"\"\"\n",
    "        focus_len: 시퀀스 뒤에서부터 몇 개 토큰을\n",
    "                   '결과/수익률 구간'이라고 보고 가중치를 줄지\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.eos = tokenizer.eos_token\n",
    "        self.focus_len = focus_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_txt = self.texts[idx]\n",
    "\n",
    "        txt = row_txt + self.eos\n",
    "\n",
    "        # max_len+1 길이로 토큰화 → x:[:-1], y:[1:] 사용\n",
    "        enc = self.tokenizer(\n",
    "            txt,\n",
    "            max_length=self.max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn_mask = enc[\"attention_mask\"][0]  # (max_len+1,)\n",
    "\n",
    "        # 언어모델용 input/target\n",
    "        x = ids[:-1].clone()       # (max_len,)\n",
    "        y = ids[1:].clone()        # (max_len,)\n",
    "        x_mask = attn_mask[:-1].clone()\n",
    "\n",
    "        # pad 위치는 loss에서 무시되도록 -100\n",
    "        y[x_mask == 0] = -100\n",
    "\n",
    "        # ----- roi_mask 생성 (결과/수익률 구간) -----\n",
    "        # 실제 토큰 길이 (pad 제외)\n",
    "        valid_len = int(x_mask.sum().item())   # 예: 380 토큰\n",
    "        roi_mask = torch.zeros_like(x_mask)    # (max_len,)\n",
    "\n",
    "        # 뒤에서 focus_len개를 결과 구간으로 설정\n",
    "        start = max(0, valid_len - self.focus_len)\n",
    "        roi_mask[start:valid_len] = 1\n",
    "\n",
    "        return x, y, x_mask, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e2f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([512])\n",
      "y shape: torch.Size([512])\n",
      "x_mask shape: torch.Size([512])\n",
      "roi_mask shape: torch.Size([512])\n",
      "x[:20]: tensor([26316,    28, 27559,   198, 14463,    28,    16,    11,  1157,    11,\n",
      "         1314,    11,  1507,    11,  1959,    11,  2548,   198,  4189,   385])\n",
      "y[:20]: tensor([   28, 27559,   198, 14463,    28,    16,    11,  1157,    11,  1314,\n",
      "           11,  1507,    11,  1959,    11,  2548,   198,  4189,   385,    28])\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "train_ds = LottoDataset(train_samples, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "x, y, x_mask, roi_mask = train_ds[0]\n",
    "\n",
    "print(\"x shape:\", x.shape)          # torch.Size([256])\n",
    "print(\"y shape:\", y.shape)          # torch.Size([256])\n",
    "print(\"x_mask shape:\", x_mask.shape)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)\n",
    "\n",
    "print(\"x[:20]:\", x[:20])\n",
    "print(\"y[:20]:\", y[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f8c7",
   "metadata": {},
   "source": [
    "DataSet 출력값 예시\n",
    "\n",
    "X TEXT:\n",
    "money=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "\n",
    "Y TEXT:\n",
    "oney=8000\n",
    "winning=1,2,3,4,5,6\n",
    "bonus=7\n",
    "###\n",
    "티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a468413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|>\n",
      "pad_token_id: 50256\n",
      "vocab_size: 50257\n",
      "\n",
      "input_ids shape: torch.Size([512])\n",
      "attention_mask shape: torch.Size([512])\n",
      "\n",
      "=== DECODED TEXT ===\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"vocab_size:\", tokenizer.vocab_size)\n",
    "\n",
    "\n",
    "# lotto_train.txt 읽기\n",
    "def load_text_samples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_samples = load_text_samples(\"lotto_train.txt\")\n",
    "\n",
    "# 샘플 하나\n",
    "example = train_samples[0]\n",
    "# print(\"=== ORIGINAL TEXT ===\")\n",
    "# print(example)\n",
    "\n",
    "# encode\n",
    "enc = tokenizer(\n",
    "    example,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = enc[\"input_ids\"][0]\n",
    "attention_mask = enc[\"attention_mask\"][0]\n",
    "\n",
    "print(\"\\ninput_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "\n",
    "# decode\n",
    "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== DECODED TEXT ===\")\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4947dc",
   "metadata": {},
   "source": [
    "# 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ae71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 샘플 수: 50000\n",
      "첫 샘플 원본:\n",
      "money=4000\n",
      "winning=1,11,15,18,29,38\n",
      "bonus=33\n",
      "###\n",
      "티켓수=4\n",
      "구매번호:\n",
      "[2,7,9,15,16,18]\n",
      "[3,6,28,35,38,44]\n",
      "[2,6,14,15,33,39]\n",
      "[2,13,27,35,36,42]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "def load_text_samples(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read().strip()\n",
    "    # 샘플 사이에 빈 줄 하나씩 있다고 가정 → \"\\n\\n\" 기준 split\n",
    "    samples = [s.strip() for s in data.split(\"\\n\\n\") if s.strip()]\n",
    "    return samples\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "print(\"train 샘플 수:\", len(train_texts))\n",
    "print(\"첫 샘플 원본:\")\n",
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8db334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([4, 512])\n",
      "y_batch shape: torch.Size([4, 512])\n",
      "mask_batch shape: torch.Size([4, 512])\n",
      "roi_mask shape: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 512  # 일단 256 정도로 가정\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 배치 하나만 꺼내서 확인해보자\n",
    "x_batch, y_batch, mask_batch, roi_mask = next(iter(train_loader))\n",
    "\n",
    "print(\"x_batch shape:\", x_batch.shape)        # (B, T) = (4, 256)\n",
    "print(\"y_batch shape:\", y_batch.shape)        # (4, 256)\n",
    "print(\"mask_batch shape:\", mask_batch.shape)  # (4, 256)\n",
    "print(\"roi_mask shape:\", roi_mask.shape)      # (4, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fabdab",
   "metadata": {},
   "source": [
    "### focus_len 마지막 증가할 가중치 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e711222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_focus_len(texts, tokenizer, max_len: int, \n",
    "                       target_tokens=(\"3개일치\", \"수익률\"),\n",
    "                       sample_size: int = 1000,\n",
    "                       quantile: float = 0.95):\n",
    "    \"\"\"\n",
    "    texts: lotto_train.txt에서 읽어온 전체 텍스트 리스트\n",
    "    target_tokens: 결과/수익률 블록을 대표하는 토큰 문자열들\n",
    "    sample_size: 몇 개 샘플만 뽑아서 통계 낼지\n",
    "    quantile: 상위 몇 %까지 커버할지 (0.95면 95퍼센타일)\n",
    "    \"\"\"\n",
    "    n = min(len(texts), sample_size)\n",
    "    lengths = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row_txt = texts[i]\n",
    "        txt = row_txt + tokenizer.eos_token\n",
    "\n",
    "        enc = tokenizer(\n",
    "            txt,\n",
    "            max_length=max_len + 1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        ids = enc[\"input_ids\"][0]           # (max_len+1,)\n",
    "        attn = enc[\"attention_mask\"][0]     # (max_len+1,)\n",
    "\n",
    "        valid_len = int(attn.sum().item())\n",
    "        ids_list = ids[:valid_len].tolist()\n",
    "\n",
    "        # 이 샘플에서 결과 블록 시작 위치를 찾는다\n",
    "        start_idx = valid_len  # 기본값: 못 찾으면 tail=0\n",
    "\n",
    "        for tok_str in target_tokens:\n",
    "            pat = tokenizer(tok_str, add_special_tokens=False)[\"input_ids\"]\n",
    "            L = len(pat)\n",
    "\n",
    "            for j in range(valid_len - L + 1):\n",
    "                if ids_list[j:j+L] == pat:\n",
    "                    start_idx = min(start_idx, j)\n",
    "                    break  # 이 토큰은 찾았으니 다음 토큰으로\n",
    "\n",
    "        tail_len = valid_len - start_idx\n",
    "        if tail_len < 0:\n",
    "            tail_len = 0\n",
    "\n",
    "        lengths.append(tail_len)\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "    print(\"샘플 개수:\", len(lengths))\n",
    "    print(\"min tail_len:\", lengths.min())\n",
    "    print(\"avg tail_len:\", lengths.mean())\n",
    "    print(\"max tail_len:\", lengths.max())\n",
    "    focus_len = int(np.quantile(lengths, quantile))\n",
    "    print(f\"{int(quantile*100)} 퍼센타일 tail_len:\", focus_len)\n",
    "\n",
    "    return focus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fee5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 1000\n",
      "min tail_len: 117\n",
      "avg tail_len: 117.176\n",
      "max tail_len: 120\n",
      "95 퍼센타일 tail_len: 118\n",
      "최종 선택된 focus_len = 118\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")\n",
    "\n",
    "focus_len = estimate_focus_len(\n",
    "    train_texts,\n",
    "    tokenizer,\n",
    "    max_len=max_len,\n",
    "    target_tokens=(\"3개일치\", \"수익률\"),\n",
    "    sample_size=1000,\n",
    "    quantile=0.95,\n",
    ")\n",
    "print(\"최종 선택된 focus_len =\", focus_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818c09",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43da2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class GPTConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        n_layer: int = 4,\n",
    "        n_head: int = 4,\n",
    "        d_model: int = 256,\n",
    "        d_ff: int = 1024,\n",
    "        max_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.max_len = max_len\n",
    "        self.dropout = dropout\n",
    "        self.pad_id = pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.d_model = config.d_model\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.qkv = nn.Linear(config.d_model, 3 * config.d_model)\n",
    "        self.proj = nn.Linear(config.d_model, config.d_model)\n",
    "\n",
    "        mask = torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\",\n",
    "            mask.view(1, 1, config.max_len, config.max_len)\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        head_dim = C // H\n",
    "\n",
    "        qkv = self.qkv(x)              # (B, T, 3C)\n",
    "        q, k, v = qkv.split(C, dim=2)  # (B, T, C) each\n",
    "\n",
    "        q = q.view(B, T, H, head_dim).transpose(1, 2)  # (B, H, T, head_dim)\n",
    "        k = k.view(B, T, H, head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, H, head_dim).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / (head_dim ** 0.5)  # (B, H, T, T)\n",
    "\n",
    "        causal_mask = self.causal_mask[:, :, :T, :T]\n",
    "        att = att.masked_fill(causal_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: (B, T) → (B, 1, 1, T)\n",
    "            pad_mask = attn_mask.view(B, 1, 1, T)\n",
    "            att = att.masked_fill(pad_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "\n",
    "        y = att @ v                    # (B, H, T, head_dim)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fea54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.d_ff, config.d_model),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = x + self.attn(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fea343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        self.pos_emb = nn.Embedding(config.max_len, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(config.n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        self.head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "\n",
    "        # (선택) 입력 임베딩과 출력 head weight tying\n",
    "        self.head.weight = self.tok_emb.weight\n",
    "\n",
    "    def forward(self, idx, attn_mask=None):\n",
    "        # idx: (B, T)\n",
    "        B, T = idx.size()\n",
    "        device = idx.device\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device)\n",
    "        pos = pos.unsqueeze(0).expand(B, T)  # (B, T)\n",
    "\n",
    "        x = self.tok_emb(idx) + self.pos_emb(pos)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b44d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, tokenizer, prompt: str, max_new_tokens: int = 200, device=\"cpu\"):\n",
    "    \n",
    "    model.eval()\n",
    "    max_len = model.config.max_len\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # 1) 처음에는 패딩 없이 실제 길이만큼만 인코딩\n",
    "    enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    x = enc[\"input_ids\"].to(device)      # (1, T0)\n",
    "    attn_mask = enc[\"attention_mask\"].to(device)  # (1, T0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 2) 모델에 넣기 전에 길이가 max_len을 넘으면 뒤에서 max_len만 유지\n",
    "        if x.size(1) > max_len:\n",
    "            x = x[:, -max_len:]\n",
    "            attn_mask = attn_mask[:, -max_len:]\n",
    "\n",
    "        # 3) forward\n",
    "        logits = model(x, attn_mask=attn_mask)        # (1, T, vocab)\n",
    "        last_logits = logits[:, -1, :]                # (1, vocab)\n",
    "\n",
    "        probs = torch.softmax(last_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "        next_token = next_id.item()\n",
    "\n",
    "        if next_token == eos_token_id:\n",
    "            break\n",
    "\n",
    "        # 4) 새 토큰 이어붙이기\n",
    "        x = torch.cat([x, next_id], dim=1)  # (1, T+1)\n",
    "        next_mask = torch.ones_like(next_id, device=device)\n",
    "        attn_mask = torch.cat([attn_mask, next_mask], dim=1)\n",
    "\n",
    "    # 5) 결과 디코딩\n",
    "    out_ids = x[0].tolist()\n",
    "    text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de740e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "train samples: 50000\n",
      "val samples: 5000\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 2) 데이터 로딩\n",
    "train_texts = load_text_samples(\"lotto_train.txt\")\n",
    "val_texts = load_text_samples(\"lotto_val.txt\")  # 없다면 주석 처리하고 train만 써도 됨\n",
    "\n",
    "print(\"train samples:\", len(train_texts))\n",
    "print(\"val samples:\", len(val_texts))\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "train_ds = LottoDataset(train_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "val_ds = LottoDataset(val_texts, tokenizer, max_len=max_len, focus_len=118)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "# 3) 모델 & optimizer & loss\n",
    "config = GPTConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    d_model=256,\n",
    "    d_ff=1024,\n",
    "    max_len=max_len,\n",
    "    dropout=0.1,\n",
    "    pad_id=pad_id,\n",
    ")\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81b8fe",
   "metadata": {},
   "source": [
    "# Eos 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e978db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|> id: 50256\n",
      "eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9653984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n",
      "\n",
      "DATASET 내부 tokenizer:\n",
      "  pad_token: <|endoftext|> id: 50256\n",
      "  eos_token: <|endoftext|> id: 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL tokenizer:\")\n",
    "print(\"  pad_token:\", tokenizer.pad_token, \"id:\", tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", tokenizer.eos_token, \"id:\", tokenizer.eos_token_id)\n",
    "\n",
    "print(\"\\nDATASET 내부 tokenizer:\")\n",
    "print(\"  pad_token:\", train_ds.tokenizer.pad_token, \"id:\", train_ds.tokenizer.pad_token_id)\n",
    "print(\"  eos_token:\", train_ds.tokenizer.eos_token, \"id:\", train_ds.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab8a79",
   "metadata": {},
   "source": [
    "#학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=2.2057, val_loss=0.7771\n",
      "[Epoch 002] train_loss=0.3692, val_loss=0.7233\n",
      "[Epoch 003] train_loss=0.3124, val_loss=0.6765\n",
      "[Epoch 004] train_loss=0.2861, val_loss=0.6450\n",
      "[Epoch 005] train_loss=0.2730, val_loss=0.6245\n",
      "[Epoch 006] train_loss=0.2652, val_loss=0.7276\n",
      "[Epoch 007] train_loss=0.2617, val_loss=0.6099\n",
      "[Epoch 008] train_loss=0.2586, val_loss=0.6104\n",
      "[Epoch 009] train_loss=0.2570, val_loss=0.6076\n",
      "[Epoch 010] train_loss=0.2560, val_loss=0.6063\n",
      "[Epoch 011] train_loss=0.2548, val_loss=0.6070\n",
      "[Epoch 012] train_loss=0.2541, val_loss=0.6057\n",
      "[Epoch 013] train_loss=0.2534, val_loss=0.6048\n",
      "[Epoch 014] train_loss=0.2529, val_loss=0.6045\n",
      "[Epoch 015] train_loss=0.2524, val_loss=0.6050\n",
      "[Epoch 016] train_loss=0.2521, val_loss=0.6044\n",
      "[Epoch 017] train_loss=0.2517, val_loss=0.6046\n",
      "[Epoch 018] train_loss=0.2515, val_loss=0.6039\n",
      "[Epoch 019] train_loss=0.2513, val_loss=0.6043\n",
      "[Epoch 020] train_loss=0.2511, val_loss=0.6033\n",
      "[Epoch 021] train_loss=0.2509, val_loss=0.6035\n",
      "[Epoch 022] train_loss=0.2508, val_loss=0.6036\n",
      "[Epoch 023] train_loss=0.2505, val_loss=0.6034\n",
      "[Epoch 024] train_loss=0.2505, val_loss=0.6032\n",
      "[Epoch 025] train_loss=0.2503, val_loss=0.6032\n",
      "[Epoch 026] train_loss=0.2503, val_loss=0.6029\n",
      "[Epoch 027] train_loss=0.2502, val_loss=0.6031\n",
      "[Epoch 028] train_loss=0.2501, val_loss=0.6029\n",
      "[Epoch 029] train_loss=0.2500, val_loss=0.6028\n",
      "[Epoch 030] train_loss=0.2500, val_loss=0.6029\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "alpha = 5.0   # 결과/수익률 구간에 줄 가중치 (5배부터 시도)\n",
    "epochs = 15\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "accum_steps = 4  # 그대로\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # ----- Train -----\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (x, y, mask, roi) in enumerate(train_loader, start=1):\n",
    "        x    = x.to(device)        # (B, T)\n",
    "        y    = y.to(device)        # (B, T)  pad는 -100\n",
    "        mask = mask.to(device)     # (B, T)\n",
    "        roi  = roi.to(device)      # (B, T)\n",
    "\n",
    "        logits = model(x, attn_mask=mask)  # (B, T, vocab)\n",
    "        B, T, V = logits.size()\n",
    "\n",
    "        # 1) 펼치기\n",
    "        logits_flat = logits.view(-1, V)   # (B*T, V)\n",
    "        y_flat      = y.view(-1)          # (B*T,)\n",
    "        roi_flat    = roi.view(-1).float()\n",
    "\n",
    "        # 2) 토큰별 CE loss (pad는 ignore_index=-100)\n",
    "        per_token_loss = F.cross_entropy(\n",
    "            logits_flat,\n",
    "            y_flat,\n",
    "            reduction=\"none\",\n",
    "            ignore_index=-100,\n",
    "        )  # (B*T,)\n",
    "\n",
    "        # 3) pad 아닌 위치\n",
    "        non_pad_mask = (y_flat != -100).float()   # pad면 0, 나머지 1\n",
    "\n",
    "        # 4) 가중치 만들기: 기본 1, roi 구간은 alpha배\n",
    "        base_w  = non_pad_mask\n",
    "        weights = base_w + roi_flat * (alpha - 1.0)\n",
    "        # pad 위치는 base_w=0 이라 그대로 0\n",
    "\n",
    "        # 5) 최종 loss: 가중 평균\n",
    "        loss = (per_token_loss * weights).sum() / (weights.sum() + 1e-8)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # gradient accumulation\n",
    "        loss = loss / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if step % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    else:\n",
    "        if (step % accum_steps) != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ----- Validation (여기는 가중치 없이, pad만 무시) -----\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, mask, roi in val_loader:\n",
    "            x    = x.to(device)\n",
    "            y    = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            logits = model(x, attn_mask=mask)\n",
    "            B, T, V = logits.size()\n",
    "\n",
    "            logits_flat = logits.view(-1, V)\n",
    "            y_flat      = y.view(-1)\n",
    "\n",
    "            per_token_loss = F.cross_entropy(\n",
    "                logits_flat,\n",
    "                y_flat,\n",
    "                reduction=\"none\",\n",
    "                ignore_index=-100,\n",
    "            )\n",
    "\n",
    "            non_pad_mask = (y_flat != -100).float()\n",
    "            loss = (per_token_loss * non_pad_mask).sum() / (non_pad_mask.sum() + 1e-8)\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {epoch:03d}] train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"lotto_gpt_epoch{epoch:03d}.pt\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"lotto_gpt_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4f961da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZHxJREFUeJzt3Qd4VFXawPF30hMgVOlVUUQQEBREXEXpuAj29klZu7Kry9qwgIArVsTO2kBcFSvYkKqICIqAiLiAgCAivSWE9GS+5z2TGWYmM8mEJDP3Tv6/57lObpl7T+7J4H3nnPcch9PpdAoAAAAAlENMed4MAAAAAAQWAAAAACoELRYAAAAAyo3AAgAAAEC5EVgAAAAAKDcCCwAAAADlRmABAAAAoNwILAAAAACUG4EFAAAAgHIjsACAMBk+fLi0bNnymN770EMPicPhkKom0O+t91DvZWmmTZtm3rt169YKK4+eS8+p5wYA+CKwAFDl6YNiKMuiRYuq9L36+eefzX1Yvnx5sX179uyRuLg4+b//+7+g7z98+LAkJyfLxRdfLFb39ttvy+TJk8VKNJiqXr16pIsBAEHFBd8FAFXDm2++6bM+ffp0mT9/frHtbdu2Ldd1XnnlFSksLDym9z7wwANy7733SiR9/vnnUr9+fTnjjDOK7dPtffr0kY8//lgyMzMlJSWl2DEfffSRZGdnlxh8hGLDhg0SExNT6YHF2rVr5Y477vDZ3qJFC8nKypL4+PhKvT4A2BGBBYAqz/9B97vvvjOBRWkPwMEeoIMpz8OotgboEkmzZ8+WAQMGBO2Sdc0118icOXPkk08+kSuvvDLgw3rNmjXlggsuKFc5EhMTJVL0d09KSorY9QHAyugKBQAh6Nmzp7Rv315Wrlwp55xzjgko7rvvPrNPv6XXh+XGjRubh94TTjhBJkyYIAUFBSXmWLj76z/55JPy8ssvm/fp+7VF4Icffig110DXR44cKbNmzTJl0/e2a9fOPNz7025cp59+unko1uv85z//KVPexqFDh2Tp0qUlBgUXXXSRVKtWzQQQgbpKLVy4UC699FJTzm+++UYuu+wyad68uVlv1qyZ/POf/zStAaUJlGPxyy+/yPnnn2+6WjVt2lQefvjhgK1DodSV1rW2zvz++++ebnDueguWY/Hll1/KX/7yF/P716pVSwYPHizr1q3zOcZ9vzdt2mTKr8dpoDVixAgTpFaU999/X7p06WLuRb169UyA/Oeff/ocs2vXLnNdvVd6Hxo1amTK7J2PsmLFCunXr585h56rVatW8re//a3Cygkg+tBiAQAh2r9/v/nGXr+N14e1Bg0amO36kKl930eNGmVe9SFzzJgxkp6eLk888USp59UHcc0/uOmmm8yD5+OPP27yEH777bdSWzmWLFliuhjdeuutUqNGDXn22WflkksukW3btkndunXNMT/++KP079/fPDyOGzfOPESPHz9ejjvuuJDrfu7cuaZsffv2DXqMPlTrw+kHH3wgBw4ckDp16nj2vfvuu+a62qrhfvjVh+lbbrnFlFPzNp577jnZvn272VcW+pB83nnnSX5+vukupuXQQE0fhv2FUlf333+/pKWlmbI8/fTTZltJuQ0LFiwwfxfHH3+8CR40ONLfpUePHrJq1apiCfuXX365eUifOHGi2f/qq6+armSPPfaYlJf+fhowaHCq59+9e7c888wz8u2335q/Aw1mlP6NaDD297//3ZRPAz9tpdO/G/e61rX+jeg91fdp0KF/awAQlBMA4OO2225z+v/zeO6555ptU6ZMKXa3MjMzi2276aabnCkpKc7s7GzPtmHDhjlbtGjhWd+yZYs5Z926dZ0HDhzwbP/444/N9k8//dSzbezYscXKpOsJCQnOTZs2ebb99NNPZvtzzz3n2TZo0CBTlj///NOzbePGjc64uLhi5wzm2muvNfegNJ9//rk553/+8x+f7WeeeaazSZMmzoKCgqD3bOLEiU6Hw+H8/fffS/y99R7qvXS74447zDHff/+9Z9uePXucNWvWNNv1Ppe1ri644AKfuvKvs6lTp3q2derUyVm/fn3n/v37feohJibGOXTo0GK/y9/+9jefc1500UXmb6A0+jtXq1Yt6P7c3FxTjvbt2zuzsrI82z/77DNz3TFjxpj1gwcPmvUnnngi6Llmzpxpjvnhhx9KLRcAuNEVCgBCpF1G9Ntgf97fjGvLw759+0y3GP1Gfv369aWe94orrpDatWt71vW9SlssStO7d2/TncetQ4cOkpqa6nmvthLoN+pDhgwx3X/cWrdubb5lD4V2KdLuVaHkRri/5fbuDrVlyxaTt3LVVVd5kq6979mRI0fMPTvrrLM0gjDfrJc19+PMM8+Url27erZpGdytIxVZV/527twpq1evNl2bvFtotB40mV3L5u/mm2/2Wdfra2uYtpqUh3Zd0pYGbb3yzgPRejv55JNN9y73PUhISDDd4w4ePBjwXO6Wjc8++0zy8vLKVS4AVQeBBQCEqEmTJuaBzJ92KdH8Au0vrw/1+lDrTvzWLjWl0TwDb+4gI9hDX0nvdb/f/V590NSuORpI+Au0LRDN99i7d29IgYUmmGugpDkU7n797iDD+0Ffu9y4H8a1m5Hes3PPPTfke+ZNcyFOPPHEYtvbtGlT4XUV6NrBrqWjiGngooFTRdX3sZZFAwv3fg2QtdvVF198Ybrzac6Qdr/TLmVuWhfaXUq7zmmOhXZxmzp1quTk5JSrjACiG4EFAIQoUJ99TWrWh7CffvrJ5C18+umnpq+6u798KMPLxsbGBtzu6u1Uee8NlX7rrv3uTznllJCO1wd1/b3feecds66v+t5OnTp5WlH023z9Bv2ee+4xyed6z9wJ0cc6JG9pKqKuKkI46qw0Oozur7/+avIwtHXjwQcfNIGQu7VI82k0V2bZsmVmgAANEjVxW5PCMzIywlZOAPZC8jYAlIN2J9FuLJrUqt/8enf/sQJNCtYHRx2JyF+gbYFoADBw4MCQr9mtWzfTPUtbKjSA0FaCf//73z4T7elD7RtvvCFDhw71bNeH/GOhc0ts3Lgx4HwXx1pXoY6WpdcOdC2lXav0235NJg8H77LoCFnedJt7v5vW0b/+9S+z6P3TwO+pp56S//73v55jtIuZLlp/Wp/a6jRjxgy5/vrrw/I7AbAXWiwAoAK+ffb+tjk3N1defPFFy5RP8zC0VWDHjh0+QYV2hSmNjiqkIxeVde4JfQDVb7/Hjh1rHtKvvvpqnzL53zP9WUcvOhYa9GgOh/eM4Np166233jrmutJgIJSuUTrSlj6Qa5CkLSJuOrnevHnzyhSQlZcOJ6yB5JQpU3y6LGk969C37jrUfBKdqNA/yNBRxdzv025Z/i0o7hYnukMBCIYWCwAoB0041j7yw4YNk3/84x/mIVpn7A5nt5bS6BCo+pCrw5/q8K7aFen55583c19o4nFp3aC0xUOHcy0L7Q6l3Y103gi9rveQq9rfXx9k77zzTtPFRnMdPvzww2POMbj77rvNPdchdW+//XbPcLP6Df2aNWuOqa60y48OkavD0urQrZoHMmjQoIDX12FqNRG+e/fuct1113mGm9U8Dr33FUkTqXWODn+aq6JJ29qtSwcY0C5fmizvHm5W77/OE6K0tahXr15m2FvtoqZ5MTNnzjTHuic21EBJAy7NR9G60kR3nTle6yqcwRIAeyGwAIBy0DkYdOQc7U7ywAMPmAdXfajWBzedXMwK9CFZv7XWB3ntS6+T0elDv36LXdpISBpYaFARKL+kJJpM7Z7oz390Jp2bQ/Mb9OHe3cdfH2C1L3/Hjh3L/Ptpq8FXX31l5mR49NFHTZ3oyEs6CpY+6B9LXelDugZdmrCsc1lokBIssNAWIR01S1tndE4M/f30wV4f8nW+ioqkLSxah/704V/LrAnxOnmj3gfNX9EgS++tlsU90pPWvwYdOmGhBlYaWGiw995775mEbaXl1xYg7fakAYcGSTrqlrYCVfTvBCB6OHTM2UgXAgAQfjoEreY/BMpPUDrhnD6M68O/PrQCAFASciwAoArQ7jneNJjQ1oiePXsGfY/Onq3dZ/QbbwAASkOLBQBUAdpdSLvJHH/88WY+g5deeskk4WqCdaA5IAAAKCtyLACgCtDEZp1PQidB0wnSNNH4kUceIagAAFQYWiwAAAAAlBs5FgAAAADKjcACAAAAQLmRYxFAYWGhmaFWZyHVCZQAAACAqsjpdJpJMnVuoJiYktskCCwC0KBCJxACAAAAIPLHH39I06ZNCSzKSlsq3DcwNTU16HF5eXkyb9486du3r5lpFfZB3dkb9Wdf1J19UXf2Rd3ZW16EnzfT09PNF+7u5+OS0GIRgLv7kwYVpQUWKSkp5hgCC3uh7uyN+rMv6s6+qDv7ou7sLc8iz5uhpAeQvA0AAACg3AgsAAAAAJQbgQUAAACAcotojsXEiRPlo48+kvXr10tycrKcddZZ8thjj0mbNm2CvueVV16R6dOny9q1a816ly5d5JFHHpGuXbt6jhk+fLi88cYbPu/r16+fzJkzpxJ/GwAAgKqnoKDA5AGgcui9jYuLk+zsbHOvK5rmbcTGxto/sPj666/ltttukzPOOEPy8/PlvvvuMxnv//vf/6RatWoB37No0SK56qqrTBCSlJRkAhF9zy+//CJNmjTxHNe/f3+ZOnWqZz0xMTEsvxMAAEBVmd9g165dcujQoUgXJervc8OGDc1opZU1v1qtWrXMNcp7/ogGFv4tCNOmTZP69evLypUr5Zxzzgn4nrfeestn/dVXX5UPP/xQFi5cKEOHDvUJJPQGAQAAoOK5gwp9dtNRi5hUuPImbs7IyJDq1auXOkHdsQQtmZmZsmfPHrPeqFGjcp3PUsPNpqWlmdc6deqE/B69GdpE5P8ebdnQP/TatWvL+eefLw8//LDUrVs34DlycnLM4j1er9LzltS0595H85/9UHf2Rv3ZF3VnX9SdfVVG3WmXnIMHD8pxxx1nnrVQefThPzc313xpXhnBm55Xg5e9e/eauvTvFlWWvxuHU0trAfoLXXjhhSbyXbJkScjvu/XWW2Xu3LmmK5R2jVIzZswwkXOrVq1k8+bNpouVRnnLli0L2IfsoYceknHjxhXb/vbbb5vzAAAA4Cjt8689Q3QmZrqb219OTo5s377dtEJpeoL/l/hXX321aQAoaX43SwUWt9xyi3zxxRcmqChtunC3Rx99VB5//HHTOtGhQ4egx/32229ywgknyIIFC6RXr14htVjoDIP79u0rdYK8+fPnS58+fZggz2aoO3uj/uyLurMv6s6+KqPuNJFY+/y3bNnS88UuKoc+qh8+fNjMfF1Z3c20Prdu3Wqef/3rU5+L69WrF1JgYYmuUCNHjpTPPvtMFi9eHHJQ8eSTT5rAQoOFkoIKdfzxx5sbsmnTpoCBhUbagaJt/fCF8gEM9ThYD3Vnb9SffVF39kXd2VdF1p12hdKHXO3zX9H9/lG8V49y3+/KoOfV8wf6GynL30xMpCMwDSpmzpwpX375pem6FAptpZgwYYJJ/j799NNLPV6bdvbv31/uhBQAAADATVtsJk+eXCE3ZNGiRebh3s6jbEW0xUKHmtU8ho8//tg072i/LlWzZk0zr4XSkZ50GFmd80Lp8LJjxowx79PKdL9Hcyh00ax5zZe45JJLTN8/zbG4++67pXXr1mYuCwAAAFRdPXv2lE6dOlVIQPDDDz8EnSKhKopoi8VLL71k+mtpBWtrgnt59913Pcds27ZNdu7c6fMezYy/9NJLfd6jXaOUJmevWbPGJIKfdNJJct1115lJ9L755huSiwAAAFBqjxr/BOZgdFQsBvqxUFeoQIvOnO3dLKTzW7hpYkmg9+jITkpbOnSUKB2PVwMQPf7ll1+WBg0aROR3BAAAgDXoM6ZO0PzMM8+Ybke66HOmvuogQvpltObd6mBC2utl8ODB5hlSe8XohM6a21tSVyiHw2HmWLvoootMwHHiiSfKJ598cszl1bnaTj31VFMGzRl+6qmnfPa/+OKL5hqacK3H6Bfvbh988IF5rz4b65QLvXv3liNHjkhlskTyNnyt2HpAdqRlyxkta0ujmq4uYQAAAFalX/Jm5RVE5NrJ8bEhj5akAcWvv/4q7du3l/Hjx5ttOmWBuvfee00PGH2A1/kcdNSrgQMHyr///W8TbEyfPl0GDRokGzZskObNmwe9xrhx40w+8BNPPCHPPfecXHPNNfL777+XaZ42pRNGX3755TJ27FhTDu2Ro7nJGiRogLRixQr5xz/+IW+++aacddZZcuDAAdNDR2lvn6uuusqUQ4McHVVK91X2YLAEFhb02Jz18sPWg/LiNZ2l0akEFgAAwNo0qDhlzNyIXPt/4/tJSkJoj7Sax5uQkGBaEzQXV61fv968aqChQ/K6aSDQsWNHz7oOHKQDDmkLhD7gBzN8+HDzUK8eeeQRefbZZ2X58uXSv3//Mv1ekyZNMqOZPvDAA2bI186dO5uyasCi19B0Ac3v+Otf/2pylVu0aCGnnXaaJ7DQ7lwXX3yx2a609aKyMT6YBaUmuYb1SsuquBkyAQAAEJz/SKM6INCdd94pbdu2lVq1apnuUOvWrTMP9CXp4DUNgj7469wP2kW/rPRaPXr08Nmm6xs3bjTD/WoQpEGDtrBce+218tZbb5nJ7JQGRBqUaDBx2WWXySuvvGJmSq9stFhYUM1kV2CRTmABAABsQLsjactBpK5dEfxHd9KgQicW1O5ROrqo5ipoDoPm8JYk3m/eB+2m5Z6LoiJpK8WqVatMPvK8efPMqKmac6wjVWkgpGVfunSp2addsu6//375/vvvQ57e4VgQWFhQalFgQYsFAACwA314DrU7UqRpVyj9xr803377relypDkK7hYMHRQoXNq2bWvK4F8mHfVUR0FVcXFxJilbF83F0IBC54bTLlBaJ9rCoYsGHdq6oV25Ro0aVWlltsdfQBUNLNKz6QoFAABQkXQkJ/3mXoME7d4UrDVBR1v66KOPTMK2PqQ/+OCDldLyEMy//vUvMxLVww8/bJK3f/75Z3n++efNSFDqs88+k99++03OOecck2w+e/ZsU742bdqY32/hwoXSt29fqV+/vlnfu3evCVYqEzkWFpSa5Ir30rJCG0MZAAAAodEuTvqN/ymnnGLmoQiWM6HJ0/rAriMuaXChEy1rAnW4dO7cWd577z0zv5uWQbs5aYK5e1oGbZ3QwOf88883AcOUKVPknXfekXbt2pm8jsWLF5uARFs4NAFch6odMGBApZaZFgsLIscCAACgcuiD9rJly3y2ec+h5t2yod2KvN12220+6/5do5wBhnM9dOhQSOXSCaP933/JJZeYrlg6KpQGCzExR9sEzj77bJNfEYgGGnPmzJFwo8XCgsixAAAAgN0QWFi5xYIcCwAAgKhw8803m5yOQIvuiwZ0hbLwPBYMNwsAABAdxo8fb/I7AtFuTtGAwMKCaqa4A4t809cu1GnqAQAAYE3169c3SzSjK5SFR4XKLSiU7LzwDWsGAAAAHCsCCwuqnhgnMUWNFORZAAAAwA4ILCxIuz4xMhQAAADshMDCopjLAgAAAHZCYGHxkaHSsvIiXRQAAACgVAQWFsVcFgAAANajM3JPnjw55O7ts2bNkqqCwMKiUpNdI0OlZdJiAQAAAOsjsLB8i0V+pIsCAAAAlIrAwqLIsQAAAKhYL7/8sjRu3FgKC33nCRs8eLD87W9/k82bN5ufGzRoINWrV5czzjhDFixYUGHX//nnn+X888+X5ORkqVu3rtx4442SkZHh2b9o0SLp2rWrVKtWTWrVqiU9evSQ33//3ez76aef5LzzzpMaNWqYmbq7dOkiK1asECshsLAo93Cz6SRvAwAAq3M6RXKPRGbRa4fosssuk/3798tXX33l2XbgwAGZM2eOXHPNNeYhf+DAgbJw4UL58ccfpX///jJo0CDZtm1buW/RkSNHpF+/flK7dm354Ycf5P333zdBy8iRI83+/Px8GTJkiJx77rmyZs0aWbZsmQk8NE9DXXvttdK0aVPz3pUrV8q9994r8fGu50WrcHXkh+UwjwUAALCNvEyRRxpH5tr37RBJqBbSofpQP2DAAHn77belV69eZtsHH3wg9erVM60BMTEx0rFjR8/xEyZMkJkzZ8onn3ziCQCO1dtvvy3Z2dkyffp00yKhnn/+eRO4PPbYYyZISEtLk7/+9a9ywgknmP1t27Y1rSvp6ekmuLnrrrvk5JNPNvtOPPFEsRpaLCyeY8FwswAAABVHWyY+/PBDycnJMetvvfWWXHnllSao0BaLO++80zzQa1ck7Q61bt26CmmxWLdunQla3EGF0q5OGjhs2LBB6tSpI8OHDzetGhpsPPPMM7Jz507Psf/85z/l+uuvl969e8ujjz5qum1ZDS0WFpWa5KoakrcBAIDlxae4Wg4ide0y0Id2p9Mpn3/+ucmh+Oabb+Tpp582+zSomD9/vjz55JPSunVrkwtx6aWXSm5uroTD1KlT5R//+IfpmvXuu+/KAw88IHPnzpVTTjlFxo4da4IiLfcXX3xh1mfMmCEXXXSRWAWBhUUx8zYAALANzQMIsTtSpCUlJcnFF19sWio2bdokbdq0kc6dO5t93377rWk1cD+sawvG1q1bK+S6bdu2lWnTpplcC3erhV5PW0q0DG6nnXaaWUaPHi3du3eXd955x3TJUieddJJZtPXiqquuMoGIlQILukJZFMnbAAAAlcP9zf/rr79ufnbTvIWPPvpIVq9ebUZhuvrqq4uNIFWeayYlJcmwYcNk7dq1JoH873//u0nK1lGotmzZYoIJTdrWkaDmzZsnGzduNDkVWVlZ5lgdNUr3aUCiSdwarFgJLRYWb7E4nJMvBYVOiY1xjQgAAACA8tEhXzWnQXMbNHhwmzRpkhl29qyzzjIJ3ffcc49JnK4IKSkpplvT7bffbrpg6foll1xirunev379ennjjTfMyFWNGjWS2267TW666SYzcpVuGzp0qOzevduUTVtdxo0bJ1ZCYGHxeSzU4ew8qZWSENHyAAAARAvtfrRjR/GckJYtW8qXX37ps00f7r2VpWuU028o3FNPPbXY+d201UJHoPKnLSYJCQlmVCktt5VZu3RVWEJcjCTHx5qfGRkKAAAAVkdgYWGpyUUjQ2XlR7ooAAAA8KLJ3zocbaClXbt2VfJe0RXK4nkWu9NzaLEAAACwmAsvvFC6desWcF+8xWbEDhcCCxvkWaRn50W6KAAAAPBSo0YNs+AoukJZGLNvAwAAwC4ILCyMuSwAAICV+Y96hKpdjwQWFkaLBQAAsCJ3DkFmZmaki4IK4K7H8uaGRDTHYuLEiWZ2Q50MJDk52UxG8thjj/lMax7I+++/Lw8++KAZR1hnSNT3DBw40CfqGjt2rLzyyity6NAh6dGjh7z00kvmWDtJTSoaFYocCwAAYCGxsbFSq1Yt2bNnj2dyN4eDyXwrg85jkZubK9nZ2RU+j4U+M2tQofWo9an1atvA4uuvvzaTjujsg/n5+XLfffdJ37595X//+59Uq1Yt4HuWLl0qV111lQlK/vrXv5rJQoYMGSKrVq2S9u3bm2Mef/xxefbZZ83Mha1atTJBSL9+/cx5dSp1u3WFSmO4WQAAYDENGzY0r+7gApVDH/6zsrLMl/CVFbxpUOGuT9sGFnPmzPFZnzZtmtSvX19Wrlwp55xzTsD3PPPMM9K/f3+56667zPqECRNk/vz58vzzz8uUKVPMzZ88ebI88MADMnjwYHPM9OnTzWyGs2bNkiuvvFLsghwLAABgVfqQ26hRI/PslpfHCJaVRe/t4sWLzbNxZQxjq+csb0uFJYebTUtLM6916tQJesyyZctk1KhRPtu0NUKDBrVlyxbZtWuX9O7d27O/Zs2aZpxhfW+gwCInJ8csbunp6Z6KLOmD4t5XWR+m6vGu5q5Dmbl8YCtYZdcdKhf1Z1/UnX1Rd/YVjrqrqAdTBO4KpT179B5Xxn3W8+sSTFn+biwTWOgvdMcdd5h8CHeXpkA0aNDWB2+6rtvd+93bgh3jT7tVjRs3rtj2efPmmT6DpdEWk8qwMU2bu2Jl575DMnv27Eq5RlVXWXWH8KD+7Iu6sy/qzr6oO3ubH6FnlrIk6FsmsNBci7Vr18qSJUvCfu3Ro0f7tIJoi0WzZs1MvkdqamqJEZxWcp8+fSqlaWrdzsPy/P+WSUFsogwc2LPCz1+VVXbdoXJRf/ZF3dkXdWdf1J295UX4mcXdk8c2gcXIkSPls88+M/3HmjZtWuKxmliye/dun2267k44cb/qNu33531Mp06dAp4zMTHRLP608kKpwFCPK6s6NVyJ5oez8yUuLo7RFipBZdUdwoP6sy/qzr6oO/ui7uwtPkLPLGW5ZkTnsdBEaw0qZs6cKV9++aUZwak03bt3l4ULF/ps0yhOtys9hwYX3sdopPX99997jrHbPBa5BYWSnRe87xsAAAAQaXGR7v6kw8V+/PHHUqNGDU8OhCZb65BaaujQodKkSROTB6Fuv/12Offcc+Wpp56SCy64QGbMmCErVqyQl19+2TNCgeZqPPzww2beCvdws40bNzbD0tpJtYQ4iXGIFDpdc1kkJ5AYBQAAAGuKaGChk9apnj198wemTp0qw4cPNz9v27bNZzIQnURPgxEdTlbnvdDgQUeE8k74vvvuu+XIkSNy4403mgnyzj77bDO0rZ3msFAxMQ4z5OyhzDxJy8qTBqn2Kj8AAACqjrhId4UqzaJFi4ptu+yyy8wSjLZajB8/3ix2l5rkCizSsxgWFQAAANYV0RwLhJ5noS0WAAAAgFURWNgksNAcCwAAAMCqCCwsLjXZ1VstLZPAAgAAANZFYGGbFov8SBcFAAAACIrAwgbJ24ocCwAAAFgZgYXF6XCzilGhAAAAYGUEFjYJLGixAAAAgJURWFgco0IBAADADggsLC41qWhUqCyStwEAAGBdBBZ2abFggjwAAABYGIGFxZG8DQAAADsgsLBJi8XhnHwpKHRGujgAAABAQAQWNpnHQh3OZvZtAAAAWBOBhcUlxMVIcnys+TmdBG4AAABYFIGFDaQmu0eGosUCAAAA1kRgYQPMZQEAAACrI7CwUZ4FLRYAAACwKgILG2AuCwAAAFgdgYWN5rKgxQIAAABWRWBhA+RYAAAAwOoILGwgNYlRoQAAAGBtBBY26grFPBYAAACwKgILGyDHAgAAAFZHYGED5FgAAADA6ggsbIB5LAAAAGB1BBa2msciP9JFAQAAAAIisLCB1GTXqFDpWXnidDojXRwAAACgGAILG7VY5BYUSk5+YaSLAwAAABRDYGED1RLiJMbh+pnZtwEAAGBFBBY2EBPj8JrLIi/SxQEAAACKIbCwCUaGAgAAgJURWNgEc1kAAADAyggsbDYyFDkWAAAAsCICC5tgLgsAAABYGYGFTZBjAQAAACsjsLBdiwWjQgEAAMB6IhpYLF68WAYNGiSNGzcWh8Mhs2bNKvH44cOHm+P8l3bt2nmOeeihh4rtP/nkk8Xu3MPNkmMBAAAAK4poYHHkyBHp2LGjvPDCCyEd/8wzz8jOnTs9yx9//CF16tSRyy67zOc4DTS8j1uyZInYnWcei2xaLAAAAGA9rqGGImTAgAFmCVXNmjXN4qYtHAcPHpQRI0b4HBcXFycNGzaUaJKaxKhQAAAAsK6IBhbl9dprr0nv3r2lRYsWPts3btxoulclJSVJ9+7dZeLEidK8efOg58nJyTGLW3p6unnNy8szSzDufSUdU1GqJ7gal9IySy4TQhPOukPFo/7si7qzL+rOvqg7e8uL8DNLWa7rcDqdTrEAzYWYOXOmDBkyJKTjd+zYYYKFt99+Wy6//HLP9i+++EIyMjKkTZs2phvUuHHj5M8//5S1a9dKjRo1Ap5L8zL0OH967pSUFLGCrYdFnl4bJ3USnTK2c0GkiwMAAIAqIDMzU66++mpJS0uT1NTU6AwstBXiqaeeMgFGQkJC0OMOHTpkWjQmTZok1113XcgtFs2aNZN9+/aVeAM1gps/f7706dNH4uNdORCV5be9R6Tfs99KjaQ4WXX/+ZV6raognHWHikf92Rd1Z1/UnX1Rd/aWF+FnFn0urlevXkiBhS27Qmks9Prrr8u1115bYlChatWqJSeddJJs2rQp6DGJiYlm8aeVF0oFhnpcedSpkWxeD2fnS0xsnMTGOCr1elVFOOoOlYf6sy/qzr6oO/ui7uwtPkLPLGW5pi3nsfj6669NoBCsBcKbdovavHmzNGrUSOwsNfloDJiRnR/RsgAAAACWCiz0oX/16tVmUVu2bDE/b9u2zayPHj1ahg4dGjBpu1u3btK+ffti++68804TeGzdulWWLl0qF110kcTGxspVV10ldpYYFytJ8UUJ3EySBwAAAIuJaFeoFStWyHnnnedZHzVqlHkdNmyYTJs2zSRfu4MMN+3f9eGHH5o5LQLZvn27CSL2798vxx13nJx99tny3XffmZ+jYfbt7Lwc5rIAAACA5UQ0sOjZs6fJlwhGgwt/Oo+FZqcHM2PGDIlWqUnxsjs9hxYLAAAAWI4tcyyqKm2xUOl0hQIAAIDFEFjYSGpRYEGOBQAAAKyGwMKOLRbZzBYNAAAAayGwsJHUJFdKDC0WAAAAsBoCC1vmWDCPBQAAAKyFwMJGyLEAAACAVRFY2DCwIMcCAAAAVkNgYbN5LBQ5FgAAALAaAgsbYR4LAAAAWBWBhY2kJrtHhSJ5GwAAANZCYGEjzGMBAAAAqyKwsGHydm5+oWTnFUS6OAAAAIAHgYWNVE+IkxiH6+f0LGbfBgAAgHUQWNhITIxDajAyFAAAACyIwMJmyLMAAACAFRFY2HZkKLpCAQAAwDoILGw7lwVDzgIAAMA6CCxshtm3AQAAYEUEFjbD7NsAAACwIgILm85lQY4FAAAArITAwmYYFQoAAABWRGBhM6lJjAoFAAAA6yGwsGlXKEaFAgAAgJUQWNgMORYAAACwIgILmyHHAgAAAFZEYGEzzGMBAAAAKyKwsGmLRUZOvhQWOiNdHAAAAMAgsLCZ1GTXqFBOp8jh7PxIFwcAAAAwCCxsJjEuVpLiXdWWnp0X6eIAAAAABoGFDZFnAQAAAKshsLDzyFBZtFgAAADAGggsbIi5LAAAAGA1BBY2xFwWAAAAsBoCCxtKTXKNDJVGVygAAABYBIGFrXMsGG4WAAAA1kBgYUPkWAAAAMBqIhpYLF68WAYNGiSNGzcWh8Mhs2bNKvH4RYsWmeP8l127dvkc98ILL0jLli0lKSlJunXrJsuXL5doQo4FAAAArCaigcWRI0ekY8eOJhAoiw0bNsjOnTs9S/369T373n33XRk1apSMHTtWVq1aZc7fr18/2bNnj0QL5rEAAACA1biygCNkwIABZikrDSRq1aoVcN+kSZPkhhtukBEjRpj1KVOmyOeffy6vv/663HvvvRJNXaGYxwIAAABWEdHA4lh16tRJcnJypH379vLQQw9Jjx49zPbc3FxZuXKljB492nNsTEyM9O7dW5YtWxb0fHouXdzS09PNa15enlmCce8r6ZjKUC3eYV4PZZZcPojl6g4Vg/qzL+rOvqg7+6Lu7C0vws8sZbmurQKLRo0amRaI008/3QQCr776qvTs2VO+//576dy5s+zbt08KCgqkQYMGPu/T9fXr1wc978SJE2XcuHHFts+bN09SUlJKLdf8+fMlnLYf0f/Gyb60DJk9e3ZYrx1twl13qFjUn31Rd/ZF3dkXdWdv8yP0zJKZmRmdgUWbNm3M4nbWWWfJ5s2b5emnn5Y333zzmM+rLRyal+HdYtGsWTPp27evpKamlhjBaSX36dNH4uNd3ZPCYfvBLHlizTeS7YyVgQP7he260SRSdYeKQf3ZF3VnX9SdfVF39pYX4WcWd0+eqAssAunatassWbLE/FyvXj2JjY2V3bt3+xyj6w0bNgx6jsTERLP408oLpQJDPa6i1C2KdXLzC6VAYiQpPjZs14424a47VCzqz76oO/ui7uyLurO3+Ag9s5Tlmrafx2L16tWmi5RKSEiQLl26yMKFCz37CwsLzXr37t0lWlRPiBOHK82CBG4AAABYQkRbLDIyMmTTpk2e9S1btphAoU6dOtK8eXPTRenPP/+U6dOnm/2TJ0+WVq1aSbt27SQ7O9vkWHz55ZcmF8JNuzQNGzbM5GFoa4a+R4e1dY8SFQ1iYhxmyNm0rDxJz86T+qlJkS4SAAAAqriIBhYrVqyQ8847z7PuznPQwGDatGlmjopt27Z59uuoT//6179MsKFJ1R06dJAFCxb4nOOKK66QvXv3ypgxY8zEeTqC1Jw5c4oldNtdanKcCSx0AQAAAKp0YKEjOjmdzqD7Nbjwdvfdd5ulNCNHjjRLNNPZt/+QLEnPyo90UQAAAAD751hUVcy+DQAAACshsLBxi4XSHAsAAAAg0ggs7N5ikUlgAQAAgMgjsLCpmim0WAAAAMA6CCxs3hWKUaEAAABgBQQWNpWa5BrQi1GhAAAAYAUEFjaVSosFAAAALITAwuaBBaNCAQAAwAoILGyKHAsAAABYCYGFzYebTc9iuFkAAABEHoGFzVssDufkS2GhM9LFAQAAQBVHYGFTqcmuUaGcTldwAQAAAEQSgYVNJcbFSlK8q/roDgUAAIBII7CIgjwLJskDAABApBFYREGeBS0WAAAAiDQCCxtjLgsAAABYBYGFjTGXBQAAAKyCwMLGUpNcI0OlZzEqFAAAACKLwMLGaLEAAACAVRBY2Bg5FgAAALAKAgsbo8UCAAAAVkFgEQXzWDDcLAAAACKNwCIKukIxQR4AAAAijcDCxlKTi0aFymZUKAAAAEQWgYWNkWMBAAAAqyCwsDFyLAAAAGAVBBY2VjPFlWORk18o2XkFkS4OAAAAqjACCxurnhAnDofr5/TsvEgXBwAAAFUYgYWNxcQ46A4FAAAASyCwiJKRodKyGBkKAAAAkUNgESUjQzFJHgAAACKJwCJaRoYixwIAAAARRGBhc8xlAQAAANsGFn/88Yds377ds758+XK544475OWXX67IsiEEzGUBAAAA2wYWV199tXz11Vfm5127dkmfPn1McHH//ffL+PHjK7qMCGEui7QshpsFAACAzQKLtWvXSteuXc3P7733nrRv316WLl0qb731lkybNq2iy4gSpCa5RoVKZ1QoAAAA2C2wyMvLk8TERPPzggUL5MILLzQ/n3zyybJz586Qz7N48WIZNGiQNG7cWBwOh8yaNavE4z/66CPTOnLcccdJamqqdO/eXebOnetzzEMPPWTO5b1ouaIVORYAAACwbWDRrl07mTJlinzzzTcyf/586d+/v9m+Y8cOqVu3bsjnOXLkiHTs2FFeeOGFkAMRDSxmz54tK1eulPPOO88EJj/++GOx8mmA416WLFki0SrVPdwso0IBAAAgglz9aMrosccek4suukieeOIJGTZsmAkO1CeffOLpIhWKAQMGmCVUkydP9ll/5JFH5OOPP5ZPP/1UTjvtNM/2uLg4adiwoVQF7sCCHAsAAADYLrDo2bOn7Nu3T9LT06V27dqe7TfeeKOkpKRIuBQWFsrhw4elTp06Pts3btxoulclJSWZ7lITJ06U5s2bBz1PTk6OWdz093J3+dIlGPe+ko6pbNXiHJ7AIpLlsBsr1B2OHfVnX9SdfVF39kXd2VtehJ9ZynJdh9PpdJb1AllZWaJvcwcRv//+u8ycOVPatm0r/fr1K+vpXAVxOMw5hgwZEvJ7Hn/8cXn00Udl/fr1Ur9+fbPtiy++kIyMDGnTpo3pBjVu3Dj5888/TcJ5jRo1Ap5H8zL0OH9vv/12WAOlY7E7S+SR1XGSHOuUR7sWRLo4AAAAiCKZmZlmRNi0tDST41zhgUXfvn3l4osvlptvvlkOHTpkkqPj4+NNK8akSZPklltuqfTAQh/6b7jhBtMVqnfv3kGP0/K1aNHClOu6664LucWiWbNm5vcp6QZqBKc5Jpr3ob9/JOw9nCNnPf61OBwi6x/qIzExrhYMlMwKdYdjR/3ZF3VnX9SdfVF39pYX4WcWfS6uV69eSIHFMXWFWrVqlTz99NPm5w8++EAaNGhgEqg//PBDGTNmzDEFFmUxY8YMuf766+X9998vMahQtWrVkpNOOkk2bdoU9Bgd4co9ypU3rbxQKjDU4ypDnRqu/HsND7MLHVIzkYfksohk3aH8qD/7ou7si7qzL+rO3uIj9MxSlmvGHGuTiLtb0bx580zrRUxMjJx55pmmW1Rleuedd2TEiBHm9YILLij1eO0WtXnzZmnUqJFEo6T4WEmMc1VjOpPkAQAAIEKOKbBo3bq1mXPijz/+MPNIaNcotWfPnlKbSPwf+levXm0WtWXLFvPztm3bzPro0aNl6NChPt2fdP2pp56Sbt26mVm/ddGmGbc777xTvv76a9m6dauZtE9Hr4qNjZWrrrpKohVzWQAAAMCWgYV2d9IH+JYtW5rhZXXkJXfrhfewr6VZsWKFOd79nlGjRpmf9fxKk6/dQYZ6+eWXJT8/X2677TbTAuFebr/9ds8x27dvN0GEJm9ffvnlZl6N7777zkyqF62YywIAAACRdkw5FpdeeqmcffbZ5sHfPYeF6tWrl2khKMuwtSXljk+bNs1nfdGiRSHlX1Q17hYLukIBAADAVoGF0gnodNEWAtW0adMyTY6HipOa5KrG9Kx8bisAAADs0xVKJ6YbP3681KxZ0wzlqouOvjRhwgSzD+FFjgUAAABs2WJx//33y2uvvWYmp+vRo4fZtmTJEjPRXHZ2tvz73/+u6HKiBORYAAAAwJaBxRtvvCGvvvqqXHjhhZ5tHTp0kCZNmsitt95KYBFmtFgAAADAll2hDhw4YGbb9qfbdB/CKzWJ5G0AAADYMLDQkaCef/75Ytt1m7ZcILxosQAAAIAtu0I9/vjjZtbrBQsWeOawWLZsmZkwb/bs2RVdRpQiNbloVKhsRoUCAACAjVoszj33XPn111/NnBWHDh0yy8UXXyy//PKLvPnmmxVfSoSUvJ2WlcedAgAAgL3msWjcuHGxJO2ffvrJjBalM2QjfMixAAAAgC1bLGAt5FgAAAAg0ggsoqgrVE5+oWTnFUS6OAAAAKiCCCyiQI3EOHE4XD+nZ5NnAQAAAIvnWGiCdkk0iRvhFxPjMMGFjgqVnpUv9WtQCwAAALBwYFGzZs1S9w8dOrS8ZcIxqJkSbwILRoYCAACA5QOLqVOnVl5JUAEjQ2XRFQoAAAARQY5FlI0Mlc5cFgAAAIgAAosowVwWAAAAiCQCiyjBXBYAAACIJAKLKJGa7EqX0QRuAAAAINwILKKtxSKTeSwAAAAQfgQWUTb7NhPkAQAAIBIILKIEORYAAACIJAKLaBsVKpuuUAAAAAg/Aoso6wrFzNsAAACIBAKLKFHTPSpUFqNCAQAAIPwILKIwebuw0Bnp4gAAAKCKIbCIshwLp1MkI5dWCwAAAIQXgUWUSIqPlcQ4V3UylwUAAADCjcAiijCXBQAAACKFwCKKMJcFAAAAIoXAIoqkJjEyFAAAACKDwCIKWyzSs5gkDwAAAOFFYBFFyLEAAABApBBYRBFyLAAAABApBBZROJdFGl2hAAAAEGYEFlGEHAsAAABUycBi8eLFMmjQIGncuLE4HA6ZNWtWqe9ZtGiRdO7cWRITE6V169Yybdq0Yse88MIL0rJlS0lKSpJu3brJ8uXLpSpITXaNCkWLBQAAAKpUYHHkyBHp2LGjCQRCsWXLFrngggvkvPPOk9WrV8sdd9wh119/vcydO9dzzLvvviujRo2SsWPHyqpVq8z5+/XrJ3v27JEq02KRnR/pogAAAKCKcX3FHSEDBgwwS6imTJkirVq1kqeeesqst23bVpYsWSJPP/20CR7UpEmT5IYbbpARI0Z43vP555/L66+/Lvfee69EM3IsAAAAUCUDi7JatmyZ9O7d22ebBhTacqFyc3Nl5cqVMnr0aM/+mJgY8x59bzA5OTlmcUtPTzeveXl5ZgnGva+kY8IpJd7hmcfCKmWyKqvVHcqG+rMv6s6+qDv7ou7sLS/Czyxlua6tAotdu3ZJgwYNfLbpugYCWVlZcvDgQSkoKAh4zPr164Oed+LEiTJu3Lhi2+fNmycpKSmllmv+/PliBfuz9b9xcjAjW2bPnh3p4tiCVeoOx4b6sy/qzr6oO/ui7uxtfoSeWTIzM6MzsKgs2sKheRluGqg0a9ZM+vbtK6mpqSVGcFrJffr0kfh4V35DJGlLxfgfv5I8p0N69eknifGxkS6SZVmt7lA21J99UXf2Rd3ZF3Vnb3kRfmZx9+SJusCiYcOGsnv3bp9tuq4P/8nJyRIbG2uWQMfoe4PREaZ08aeVF0oFhnpcZasdGycOh4jTKZJZIFI9JfJlsjqr1B2ODfVnX9SdfVF39kXd2Vt8hJ5ZynJNW81j0b17d1m4cKHPNo3gdLtKSEiQLl26+BxTWFho1t3HRLOYGIfUSHTFiulZjAwFAACA8IloYJGRkWGGjdXFPZys/rxt2zZPF6WhQ4d6jr/55pvlt99+k7vvvtvkTLz44ovy3nvvyT//+U/PMdql6ZVXXpE33nhD1q1bJ7fccosZ1tY9SlS0Sy0acpa5LAAAABBOEe0KtWLFCjMnhZs7z2HYsGFm4rudO3d6ggylQ83q0LEaSDzzzDPStGlTefXVVz1DzaorrrhC9u7dK2PGjDHJ3p06dZI5c+YUS+iO5rksth/MkvRsRjsCAABAFQksevbsKU5NCAgi0Kza+p4ff/yxxPOOHDnSLFWRey4LTeQGAAAAwsVWORYow+zbBBYAAAAIIwKLKJOa7GqEIscCAAAA4URgEa0tFtmMCgUAAIDwIbCI0hyLtExyLAAAABA+BBZRpmbRpHiMCgUAAIBwIrCI0q5Q5FgAAAAgnAgsonW4WeaxAAAAQBgRWEQZZt4GAABAJBBYRJmaRcPNpmcxKhQAAADCh8AiSlsstCtUYWHwWc0BAACAikRgEaU5Fk6nSEYurRYAAAAIDwKLKJMUHyuJca5qZS4LAAAAhAuBRZR3hwIAAADCgcAiCjGXBQAAAMKNwCIKpSYxMhQAAADCi8Aiilss0rPoCgUAAIDwILCIQuRYAAAAINwILKIQORYAAAAINwKLKJ7Lgq5QAAAACBcCiyhEiwUAAADCjcAiCqUmF40Klc3M2wAAAAgPAosoRIsFAAAAwo3AIgqRYwEAAIBwI7CI4uFm05jHAgAAAGFCYBHNE+RlM0EeAAAAwoPAIopbLLLzCiUnvyDSxQEAAEAVQGARhWokxonD4fo5PYuRoQAAAFD5CCyiUEyMwwQXijwLAAAAhAOBRZR3hyLPAgAAAOFAYBGlmMsCAAAA4URgEaWYywIAAADhRGAR7UPOMpcFAAAAwoDAIkqlJruSt9OzGRUKAAAAlY/Aworyc0WcznKdghwLAAAAhBOBhRV986TIy+eK/PyBSMGxtTiQYwEAAIBwIrCwmsICkR/fEtn5k8iH14k820lk2YsiOYfLdJqaKa4cC+axAAAAQJUJLF544QVp2bKlJCUlSbdu3WT58uVBj+3Zs6c4HI5iywUXXOA5Zvjw4cX29+/fX2whJlbkpsUi590vklJPJO0PkbmjRSa1E5k/ViR9Z9laLLLzKrnAAAAAgAUCi3fffVdGjRolY8eOlVWrVknHjh2lX79+smfPnoDHf/TRR7Jz507PsnbtWomNjZXLLrvM5zgNJLyPe+edd8Q2qtUVOfdukX+uFRn0jEjdE0Vy0kS+nSwy+VSRWbeK7P5fiacgxwIAAABVKrCYNGmS3HDDDTJixAg55ZRTZMqUKZKSkiKvv/56wOPr1KkjDRs29Czz5883x/sHFomJiT7H1a5dW2wnPlmky3CR25aLXPmOSPOzRArzRFa/JfJSd5H/XiLy26KAid6eUaGyGBUKAAAAlc/19Bkhubm5snLlShk9erRnW0xMjPTu3VuWLVsW0jlee+01ufLKK6VatWo+2xctWiT169c3AcX5558vDz/8sNStWzfgOXJycszilp6ebl7z8vLMEox7X0nHVJgT+pjF8edKifn+RXGs/1QcmxaIbFogzganSsGZt4qz7RCRWFcXqJQ4h3lNy8oNT/lsJqx1hwpH/dkXdWdf1J19UXf2lhfhZ5ayXNfhdJZzXNNy2LFjhzRp0kSWLl0q3bt392y/++675euvv5bvv/++xPdrLobmZOhxXbt29WyfMWOGacVo1aqVbN68We677z6pXr26CVa025S/hx56SMaNG1ds+9tvv23OY0UpOXvkhD1zpPmBxRJXmGu2ZcXXkc3H9ZPf6/WU/QXJMmZlnDjEKZPOLJAYV5wBAAAAhCwzM1OuvvpqSUtLk9TU1OgNLG666SYTLKxZs6bE43777Tc54YQTZMGCBdKrV6+QWiyaNWsm+/btK/EGagSnXbH69Okj8fGuloKwyzwgMaumScyKV8VxxJWX4kysIXkdh8o5i0+WXVJXVt1/ntQoSuaGheoOx4z6sy/qzr6oO/ui7uwtL8LPLPpcXK9evZACi4h2hdJCagvC7t27fbbruuZFlOTIkSOmZWL8+PGlXuf4448319q0aVPAwELzMXTxp5UXSgWGelylqNlA5Lx7RM6+XeTn90SWPieOfb9KwvIX5JvEWPmksLvk7awv8SedEZnyWVxE6w7lRv3ZF3VnX9SdfVF39hYfoWeWslwzosnbCQkJ0qVLF1m4cKFnW2FhoVn3bsEI5P333zetDP/3f/9X6nW2b98u+/fvl0aNGknUik8S6TxU5NbvRa5+T6TF2RLvKJBLYpdIg7d7i7x5kcjmL8s9ozdKkZ0usupNkcO+wTIAAEC0i/ioUDrU7CuvvCJvvPGGrFu3Tm655RbTGqGjRKmhQ4f6JHd7J20PGTKkWEJ2RkaG3HXXXfLdd9/J1q1bTZAyePBgad26tRnGNurFxIic1E9kxOdya8qT8mnBmeJ0xLiCCg0uppwtsnJamSfcQwgO/SHyWl+RT0aKvNZb5ODv3DYAAFBlRLQrlLriiitk7969MmbMGNm1a5d06tRJ5syZIw0aNDD7t23bZkaK8rZhwwZZsmSJzJs3r9j5tGuV5lxooHLo0CFp3Lix9O3bVyZMmBCwu1M021X9FPn7gX9I6l/ry7kHPhRZNV1k91qRT28XmXu/SPtLRLoME2ncWcRBdne56Ezpb10ukrHLtX5om8i0v4oM/0ykdosKqU8AAAAri3hgoUaOHGmWQHTYWH9t2rSRYDnnycnJMnfu3Aovox2lJrv6xO2ObSgy4FGRnve4uumsekNk/ybXqy4NTxXpPEykw+UiSTUjXWz7+XWeyPvDRfKOiBzXVmTw8yIzb3Ld42kXFAUXLSNdSgAAgOjuCoXK4559Oz2raPzh5NoiPf4hMnKFyPDZIqdeLhKbKLLrZ5HZd4o82cY1q/e278nFCNWK10XeudIVVLQ6V+S6uSJNTxcZ9plrxvS0P0SmXiByYEtlVTMAAIAlEFhEsdQkv8DCTbs9tewhcskrIv9aL9L/Udc37flZrlm9X+8r8mJ3ke9eMsPZIoDCQpH5Y0U++6eIs0Ck49Ui13xwtMUntZGrpaLeSSLp210tFwd+41YCAICoRWBRBVos0vwDC28pdUTOvEXk1mUi180X6XSNSFyyyN51InPuFXnqZJEPbxDZuoRWDLe8bJGPrhf5drJrvedokSEvisQl+N7bGg1dLRcmuPjTlXOxf3PlVDYAAECEEVhEsdRkVwpNenZ+6QdrK0azrq4H5Ds3iFzwlCv3oiDHNT+GfuP+/Oki3z4rcmSfVFnagvPmEJG1H4rExIkMeUmk573Bk99rNBAZ/rlIvTYEFwAAIKoRWFT1FotAtDvPGdeL3PSNyA1fuRK7E6q7kpHnP+hqxXhvmMjmr1xdgqoKzZN4rY/ItmUiiaki//ehSKerS39f9fqublHHnSxyeIcrSNu3KRwlBgAACBsCi6qYYxEq/Ra+SWeRC5915WIMetY1NG1hnsj/Zrm+uX/uNJHFT4ocLhpmNVptXynyam9XcJXaVORvc0WO7xn6+zW40G5RmstyeGdRcLGxMksMAAAQVgQWUeyYWywCSazhmvPixq9cLRnaoqHf2h/cKvLlBJFJp4hMHyyy5GmRHT+KFBZI1Fj3mSsQyNwn0rCDyPULRBqcUvbzVD/O1XJR/xTXfBeac7H318ooMQAAQNWcxwKVO49FenYFBBbeGnVw5WD0meBqudCZvP/4XuS3Ra7FPbRtq3Nc3+rrUruVPSfh05Gx5ujM706RE/uKXDpVJLH6sZ+vWj2RYZ+KvHGhyJ5fRN74a1FLxkkVWWoAAICwI7CIYhXaYhFIQoorx0AX7dazaaHIlq9FtnwjknVQ5H8fuxZVq/nRIEPne9AHbCvTFhednfz7l1zrp/9NZMATIrEV8JFxBxfTL3TNhO6eRO+4NuU/NwAAQIQQWFSBHIvsvELJyS+QxLjYyrtYvRNdy5k3ixTkubpDuVsw/lgucmibyKrprkXpiFPuQKN5d5GEamIZuZkiH90gsv4z13rvcSI9bq/YFpdqdUWGfuLqPrb7Z1dwoS0X9U+uuGsAAACEEYFFFKuRFGeehZ1OTeDOl+NqVGJg4S023jV0rS7n3i2Sk+EaSckdaOi39Drbty5LnxOJTRBp2vVooNH4tIppGTgWGXtdM2n/ucI1K/lFU0TaX1w519LgYpgGFxe67oUJLj49tvwNAACACCOwiGIxMQ6pnhgnh7PzTZ7FcTUSI1MQzUk4sY9rURl7RLYsFvntK5HNi1wzU/++xLV89bArKbzlX44GGtoSEo78DO3O9dalroR0zRG58h2RFt0r95o6QaG75WLXGpE3BhFcAAAAWyKwqAJ5FhpYVFqexbHQoVdPvdS1aHPKgd9cQYa2ZmjAkZ0msuFz16JS6rm+xa/fTqR+W5EG7VxzQpQnidrf70tFZlztyg2p3VLkmg9F6rWWsDDBxceu4Xt3/lSU0K0tF+3Cc30AAIAKQGBRJfIsso59LovKpi0RdU9wLTqErSZN71xd1G3qa5Ft37mGedWAQxdvtVq4hm41QUfRUre1SFxC2cqgs2jP1NyQXJGmZ4hcNSP8yeXu4GK6BherXUPRajcpzUUBAACwAQKLKFfpI0NVtJhYkSZdXMtf/iWSlyWy538ie9aJ7NbXoiVjt8ih313Lr194vT/e1XVKWzbcwYYGHjWba98w32s5nRKz9FmRr8a71tsOErn4FZH4ZIkI7X41VCcevMiV/K5D0hJcAAAAmyCwiHKpya4qTs/OF1vSh3x3oOHtyP6jAYfOB2Fe14nkpB8NPuTDo8cnVHd1nyrqSuWoc5J0+GOaxK7+yrX/zNtE+k5wBTaRpMHFte7gYpUr50JzMHTuEAAAAAsjsKgiLRaW7QpVnhGVWv3Ftbhpvkba9qOBhWnhWCeyb4NIboZrpCddiv7wW5lp7xziGPCYSLebxDKSa4lcO1PkvxeL/LmyKLj4WKRxp0iXDAAAICgCiyoyl0XUBRbB8jVqNXMtJ/U7ul3n1dAE8d3ulo3/iXP3L5J55IgkXvikxLUfLJbjDi7e1OBihWvUKIILAABgYQQWUc52ORaVNa+GzmrtNbN1fl6eLJg9Wwa2GSiWlVTzaMvF9h9c8130GisSl2TaWsRZ6GqlMT8Hei1qxQnlWEeMaz4RvVfmNcjPcYmlH6N5Lv75LAAAIOoRWES5VHdXqOwqHFjYWVKqyP99JPLfS0S2Lxf5fJTYQkycb5DhiHXlr3heY46++uzzW/c+zuv9seKQrrt3Sey7/3W1VJnAqdA3iPIJpgp9txfb5nWcOI6Ww++6JZc7yO/pfQ73ulkcfut+i+ecJS06v4vDa54Xv5/Ni8Pv5xD2uX8OFoyWtC9ocOt6jSkokOP3/E9iftjuCkbd13LfD/f1g/1sXt2/uwS+D+5r+5RVStgW4D3+x3hfI2j5vOrV+9iA+4rWva/rf++CbvPbV+w+e93PUP7WQj2moEBScva45vqJ88pH87+XAbeXUBclnSPwiaX8/OZGCjhXUmnH+H92/I8r4bNV4meyEuTlS1LuAZH0nSLx8UE+/yX9uxDCMUE/dyF+5gJ9Bo9e3K88Jd370o4N5V6XUg+h1pPT/3dxhr7fe19+vsQW5IgdEFhEOVosoiS4uPYjkYXjXV26fB6wAj1o+e8L9GDm96oP1IV5riF3tetYfo7r1aznlvBzrutY/38sC/NdSyXR36aR/pBWaZdAJdHHUTOI8p/cYrvRx1EzzamOjQHb1Z3pIPxLpEuCY62/7tVOFJGLxOoILKrKqFBZNh0VCi6JNUQGPmHdu6HzjwQLQnSfs8Dr1d1S4L2t6FW/oSm2TYMe3+Pz83Ll57W/yKkdOkhcXHzgb4x9gq5A3xa7t/kFZ6YFo6RyFvqVzfv3CnCsz/HeLSV+rShBl9L2aytLSd8AOsu2z+c4/yBUSg5QA3276fda6HTKjh07pHGjhhJjtnm3Lolfq1Kgrnx+3fqKtaYE+jayhG8o/b/FDLbNpzXM+/peZfVvNfP8LMGPC3Zvi91D937/3yfIe3xa5YL9HTnL9HfodBZIQX6exMbF6bAXJdw3/+3Fbnrp7wlaT0EPkNCV9q1xKMe4/17lGD5XIewrU8tF6ceaUjkLxeEoqrlArV2W4vfZg20QWEQ5WiwQFtrVJyY5bHOAOPPyZNuu2dK+08CjzfqwhYK8PFk5e7Y0GDhQYqg7W9HctNmamzZwoMRTd9Fbd/7dGEP6uazdj/zWyxJI+ZRPSiiXhLAe8AKhXT/oex3FNwfrRlfiMUePy8vPk6Vz5kp/sT4Ci6oyKhQ5FgAAoDTH8rAfTlYvX6WIlULNWbQBhm6pQvNYFBbSnAgAAIDKQWBRRUaF0pjiSC55FgAAAKgcBBZRLik+VhLiXNVcpeeyAAAAQKUisKhSs2/TYgEAAIDKQWBRBdQsGnKWFgsAAABUFgKLKoDZtwEAAFDZCCyqAOayAAAAQGUjsKhSORYkbwMAAKByEFhUsbksAAAAgMpAYFEFpBYlb6dnMyoUAAAAKgeBRRVAjgUAAAAqG4FFFUCOBQAAAKpEYPHCCy9Iy5YtJSkpSbp16ybLly8Peuy0adPE4XD4LPo+b06nU8aMGSONGjWS5ORk6d27t2zcuFGqKlosAAAAEPWBxbvvviujRo2SsWPHyqpVq6Rjx47Sr18/2bNnT9D3pKamys6dOz3L77//7rP/8ccfl2effVamTJki33//vVSrVs2cMzs7W6oi5rEAAABA1AcWkyZNkhtuuEFGjBghp5xyigkGUlJS5PXXXw/6Hm2laNiwoWdp0KCBT2vF5MmT5YEHHpDBgwdLhw4dZPr06bJjxw6ZNWuWVEW0WAAAAKCyuYYLipDc3FxZuXKljB492rMtJibGdF1atmxZ0PdlZGRIixYtpLCwUDp37iyPPPKItGvXzuzbsmWL7Nq1y5zDrWbNmqaLlZ7zyiuvLHa+nJwcs7ilp6eb17y8PLME495X0jFWUDQolBlu1uplDRe71B0Co/7si7qzL+rOvqg7e8uL8DNLWa4b0cBi3759UlBQ4NPioHR9/fr1Ad/Tpk0b05qhLRFpaWny5JNPyllnnSW//PKLNG3a1AQV7nP4n9O9z9/EiRNl3LhxxbbPmzfPtJ6UZv78+WJlmWaU2TjJyiuUTz6bLXERb6eyDqvXHUpG/dkXdWdf1J19UXf2Nj9CzyyZmZn2CCyORffu3c3ipkFF27Zt5T//+Y9MmDDhmM6pLSaa5+HdYtGsWTPp27evyecoKYLTSu7Tp4/Ex7smobOigkKnjP7B9cfYo2cvqVs9Uao6u9QdAqP+7Iu6sy/qzr6oO3vLi/Azi7snj+UDi3r16klsbKzs3r3bZ7uua+5EKPQGn3baabJp0yaz7n6fnkNHhfI+Z6dOnQKeIzEx0SyBzh1KBYZ6XKRoyWokxcnh7Hw5ki/S0MJlDTer1x1KRv3ZF3VnX9SdfVF39hYfoWeWslwzop1iEhISpEuXLrJw4ULPNs2b0HXvVomSaFeqn3/+2RNEtGrVygQX3ufUSEtHhwr1nNGIuSwAAABQmSLeFUq7IA0bNkxOP/106dq1qxnR6ciRI2aUKDV06FBp0qSJyYNQ48ePlzPPPFNat24thw4dkieeeMIMN3v99dd7Roy644475OGHH5YTTzzRBBoPPvigNG7cWIYMGSJVlY4M9eehLEnLIlkZAAAAURhYXHHFFbJ3714zoZ0mV2t3pTlz5niSr7dt22ZGinI7ePCgGZ5Wj61du7Zp8Vi6dKkZqtbt7rvvNsHJjTfeaIKPs88+25zTfyK9qiS1aGio9GyTyQ0AAABEV2ChRo4caZZAFi1a5LP+9NNPm6Uk2mqhLRu6wIW5LAAAAFCZGHi0iiDHAgAAAJWJwKKKtVjoJHkAAABARSOwqCJS3YFFNoEFAAAAKh6BRRVBjgUAAAAqE4FFVRsVKotRoQAAAFDxCCyqCFosAAAAUJkILKpa8jY5FgAAAKgEBBZVbLhZZt4GAABAZSCwqILDzTqdzkgXBwAAAFGGwKKKDTdb6BTJyCGBGwAAABWLwKKKSIqPlYQ4V3WnZxNYAAAAoGIRWFTFPItMJskDAABAxSKwqEJquueyYGQoAAAAVDACiyqYZ8HIUAAAAKhoBBZVdGQoAAAAoCIRWFQhzGUBAACAykJgUSVn32ZUKAAAAFQsAosqJLUoefvzNTtk4brdTJQHAACACkNgUYX85cTjJDEuRjbvPSLXvbFCBj67RD5bs0MKdNY8AAAAoBwILKqQM4+vK9/cc57cdO7xUi0hVtbtTJeRb/8ofZ7+Wt5f8YfkFRRGuogAAACwKQKLKqZ+jSQZPaCtfHvv+XJH7xNN3sVve4/IXR+skZ5PLJLpy7ZKdl5BpIsJAAAAmyGwqKJqpSTIHb1PMgHG6AEnS73qifLnoSwZ8/EvcvZjX8l/vt4sGTkkeQMAACA0BBZVXPXEOLnp3BNkyT3nyfjB7aRJrWTZl5EjE79YLz0e/VImL/hVDmXmRrqYAAAAsDgCCxhJ8bEytHtLWXRXT3ni0g5yfL1qZobuyQs2mgBj4ux1sudwNncLAAAAARFYwEd8bIxcdnozmT/qXHn+6tOkbaNUOZJbIP9Z/Jv85bGvZMzHa2X7wUzuGgAAAHwQWCCg2BiH/LVDY5n9j7PltWGny2nNa0lOfqFMX/a7SfK+8/2fZPPeDO4eAAAADNeMaUAQDodDerVtIOefXF+Wbd4vLyzaJN9u2i8frNwuH67aLgNPbSS39WwtpzRO5R4CAABUYQQWCDnAOKt1PbOs2nZQXvxqkyxYt0c+X7PTLL1Ori+Xn9FMurSobUaYAgAAQNVCYIEy69y8trw67Awzwd4LX22Sz3/eKQvX7zGLal4nRTo3ryWnNa9tjj25UQ2TuwEAAIDoRWCBY6aJ3c9f3VlG7c2QaUu3yne/7ZeNezJk24FMs8xavcMclxQfIx2a1jJBhgYcnWnVAAAAiDoEFii344+rLuMHtzc/p2fnyepth0x3qVXbDsnqbQclPTtflm85YBY3d6uGBhmmVaNhDYmjVQMAAMC2CCxQoVKT4uWck44ziyosdMpv+zJk1e/uYONgwFaN5PhY6dC0ZlH3KVo1AAAA7IbAApUqJsYhrevXMIsmd5fUqvH9lgNm8W/VaNe4pjSqlSSNaiZJw5rJ0qBGIq0bAAAAFkNgAdu0arjFOESOq5FogoxGqUk+QYe+6lK/RpIkxJEwDgAAEC4EFrB8q8Zve4/IrrRs2ZGWJbvTsyWvwCm703PM8lOQczocYoa9dQcajWomS8OinxumJslx1eMkvzCsvyYAAEBUI7CALVo13LR1Y/+RXNmZliU707JNwKGv3uu65BYUyt7DOWZZsz0tyFXi5P5VC6RmcrzPkqpLku82s6T4btfRrnR+DwAAAFgksHjhhRfkiSeekF27dknHjh3lueeek65duwY89pVXXpHp06fL2rVrzXqXLl3kkUce8Tl++PDh8sYbb/i8r1+/fjJnzpxK/k0QjtYN7QalS4emgY9xOl3BR6Cgw/2zLrn5hZKdp4ur9aOsEmJjTBBSMzmu6LUoMEmKl+SEWEmMizHHJMbHSGJcrOmapdu8fw60zRwfG2te9f36OwMAAFhdxAOLd999V0aNGiVTpkyRbt26yeTJk00QsGHDBqlfv36x4xctWiRXXXWVnHXWWZKUlCSPPfaY9O3bV3755Rdp0qSJ57j+/fvL1KlTPeuJicwGXVVoK4J2g9KlfZOaAY/Jzc2VDz/9Qrqe3VMy80TSsvLMol2w3D97thUtR4/Jl4JCp2kV2ZeRY5bKFB/r8AQeGmiY17gYM+mga5vj6HpsjMRrcBLre4z/se7jErz2xzgcEhvjkLgYhwlmzKvDIXGxRa8xrv0+iyPIttij+/S9GhuZV4IkAACiVsQDi0mTJskNN9wgI0aMMOsaYHz++efy+uuvy7333lvs+Lfeestn/dVXX5UPP/xQFi5cKEOHDvUJJBo2bBiG3wB2DT5S4lwjT8XHx5fpvdoikpGTXxR05PsEIO7gJCe/UHLyCkzwkZNX6Fo3S4F51dYS16tr/eg217rTefR6mlOSV5AvUrnxS9h4ggyHw+TCuIMP/dkdhOg2rSPvY2NivN4nTsk8EisvbF4qsbExEuu1z3U+17onsDEBz9HzuoMe9/V13WwvOo/DU56i9aK/GYfXup5T13VNj/Pe5yr70XO436t7PduKfjb7ivKC3O8ptq3o56Pbj14z0Hm8y2TWzDbv87uOEf/zF73Ptevo+9zld52t+Hn9r232uo/3KaNIQX6+7MwU2bg7Q+Lj43zOdfT8R89XtNf3fEUr3tf0fr+7/EevH/g9RYeUfIxXOYr9HGi/5zhHgG3e56ElEkD0iWhgod8ar1y5UkaPHu3ZFhMTI71795Zly5aFdI7MzEzJy8uTOnXqFGvZ0BaP2rVry/nnny8PP/yw1K1bN+A5cnJyzOKWnp5uXvW8ugTj3lfSMbCm8tZdUqxIUvV4aVBdg5LkCi2bBi75hU6/AMQVdGiQoT9rwGKW/ELPtryibT7r+YG3mXX38UXHFDrFtMT4LM6yres5SqPHFJrIKYSDS+SQXVkZ5TwHIiNOHv1pKTffS0nBSaDAREo5Jtg5/IMu9z7vIK5YebyOy8mNlfFrFnmCsWDl8F4p6bhAv3fAmxLkmID3xO+o4vfE92zB9ge6T94bwhEaegfUJZeplP1OpxxKi5U3tn8fclBbEbFvoGsFO23guiz7+UN9b0kH+P8NFb9u2U7rcIRw/hI26XNBbEaM9InQ82ZZnpUiGljs27dPCgoKpEGDBj7bdX39+vUhneOee+6Rxo0bm2DEuxvUxRdfLK1atZLNmzfLfffdJwMGDDDBSmxsbLFzTJw4UcaNG1ds+7x58yQlJaXUMsyfPz+kssJ6oqXu4oqWEkOc2KIlofLKofFCYdFrgdN33VkUVJiQwv0aZJ/3e4KvO45uL9rmPod59XqfZ5/ftVxBTvDruMro8LQgmYHEApTd/bP7HgTb7w6liq0H+NnnnCW8p/g5/Mrrfx6/chQ7V4DzeurX75hA5/A+1v849zaf9wXZ5jmX/7X87okEOda1ap9WAf/7XGxj8HdKeDkkIy83zNdExXDIlsPBBjOB1bWq4YjYM4t+iW+brlDl8eijj8qMGTNM64TmW7hdeeWVnp9PPfVU6dChg5xwwgnmuF69ehU7j7aYaJ6Hd4tFs2bNTO5GampqiRGcVnKfPn3K3J0GkUXd2Rv1Z1+RqDv9ts83uHIWD4iKDjgafBWt+wVzXmctti1wMBb8OO9r+m3yOlfwY7x/v0DX97+2b2Dm9fuVdE2v4/Pz82Xp0mXSvXt3iY07+vjgf71AZSypXP6/n3cZAu3z3+B7b3x3hlonpR0T7N5WKp+/vWB17Lvf9z1Hy6pf4q5e/ZMZICfQF6wBLh16MUMKgH3LFMr1ynLeYOcoSzmcZTjYWebfz1mucmj9/f7rLxF73nT35LF8YFGvXj3zB757926f7bpeWn7Ek08+aQKLBQsWmMChJMcff7y51qZNmwIGFpqPESi5WysvlAoM9ThYD3Vnb9SffVF39gwKt1YTade0Nv/Ps2HdOf9YLQM7NKbubFp/s/eujdi/m2W5ZkSnJk5ISDDDxWritVthYaFZ129Egnn88cdlwoQJZvjY008/vdTrbN++Xfbv3y+NGjWqsLIDAAAAsEhgobQLks5NofNOrFu3Tm655RY5cuSIZ5QoHenJO7lbh5d98MEHzahRLVu2NHNf6JKR4Uri1Ne77rpLvvvuO9m6dasJUgYPHiytW7c2w9gCAAAAqHgRz7G44oorZO/evTJmzBgTIHTq1Mm0RLgTurdt22ZGinJ76aWXzGhSl156qc95xo4dKw899JDpWrVmzRoTqBw6dMgkdmuuhLZwMJcFAAAAEKWBhRo5cqRZAtGEa2/aClGS5ORkmTt3boWWDwAAAIDFu0IBAAAAsD8CCwAAAADlRmABAAAAoNwILAAAAACUG4EFAAAAgHIjsAAAAABQbgQWAAAAAMqNwAIAAABAuRFYAAAAACg3AgsAAAAA5UZgAQAAAKDc4sp/iujjdDrNa3p6eonH5eXlSWZmpjkuPj4+TKVDRaDu7I36sy/qzr6oO/ui7uwtL8LPm+7nYffzcUkILAI4fPiweW3WrFlF1w0AAABgy+fjmjVrlniMwxlK+FHFFBYWyo4dO6RGjRricDhKjOA0+Pjjjz8kNTU1rGVE+VB39kb92Rd1Z1/UnX1Rd/aWHuHnTQ0VNKho3LixxMSUnEVBi0UAetOaNm0a8g3XSiawsCfqzt6oP/ui7uyLurMv6s7eUiP4vFlaS4UbydsAAAAAyo3AAgAAAEC5EViUQ2JioowdO9a8wl6oO3uj/uyLurMv6s6+qDt7S7TR8ybJ2wAAAADKjRYLAAAAAOVGYAEAAACg3AgsAAAAAJQbgUU5vPDCC9KyZUtJSkqSbt26yfLly8tfI6hUDz30kJn00Hs5+eSTuesWtHjxYhk0aJCZkEfradasWcUm7BkzZow0atRIkpOTpXfv3rJx48aIlRdlq7/hw4cX+yz279+f2xhhEydOlDPOOMNMEFu/fn0ZMmSIbNiwweeY7Oxsue2226Ru3bpSvXp1ueSSS2T37t0RKzPKVn89e/Ys9tm7+eabuY0R9tJLL0mHDh08c1V0795dvvjiC9t97ggsjtG7774ro0aNMln6q1atko4dO0q/fv1kz549FVtDqHDt2rWTnTt3epYlS5Zwly3oyJEj5nOlAXwgjz/+uDz77LMyZcoU+f7776VatWrmM6j/+ML69ac0kPD+LL7zzjthLSOK+/rrr83Dy3fffSfz58+XvLw86du3r6lPt3/+85/y6aefyvvvv2+O37Fjh1x88cXcTpvUn7rhhht8Pnv67ykiq2nTpvLoo4/KypUrZcWKFXL++efL4MGD5ZdffrHX586JY9K1a1fnbbfd5lkvKChwNm7c2Dlx4kTuqIWNHTvW2bFjx0gXA2Wk/1TNnDnTs15YWOhs2LCh84knnvBsO3TokDMxMdH5zjvvcH8tXn9q2LBhzsGDB0esTAjNnj17TP19/fXXns9ZfHy88/333/ccs27dOnPMsmXLuK0Wrz917rnnOm+//faIlguhqV27tvPVV1+11eeOFotjkJubayJK7XrhFhMTY9aXLVtWkXEfKoF2l9HuGccff7xcc801sm3bNu6zzWzZskV27drl8xmsWbOm6ZLIZ9A+Fi1aZLprtGnTRm655RbZv39/pIsEP2lpaea1Tp065lX/36ffgnt/9rQ7afPmzfns2aD+3N566y2pV6+etG/fXkaPHi2ZmZkRKiECKSgokBkzZpiWJu0SZafPXVykC2BH+/btM5XeoEEDn+26vn79+oiVC6XTB89p06aZBxlt/h03bpz85S9/kbVr15o+qbAHDSpUoM+gex+sTbtBaTN+q1atZPPmzXLffffJgAEDzP8kY2NjI108iEhhYaHccccd0qNHD/MAqvTzlZCQILVq1fK5R3z27FF/6uqrr5YWLVqYL9jWrFkj99xzj8nD+OijjyJaXoj8/PPPJpDQLr2aRzFz5kw55ZRTZPXq1bb53BFYoErRBxc3TZLSQEP/gX3vvffkuuuui2jZgKrkyiuv9Px86qmnms/jCSecYFoxevXqFdGywUX76uuXLuShRVf93XjjjT6fPR0AQz9zGuDrZxCR06ZNGxNEaEvTBx98IMOGDTP5FHZCV6hjoM2H+o2afza+rjds2LCi6gZhoNH/SSedJJs2beJ+24j7c8ZnMHpo10T9t5XPojWMHDlSPvvsM/nqq69MUqn3Z0+7Ax86dMjneP7/Z4/6C0S/YFN89iIvISFBWrduLV26dDEjfOkAGM8884ytPncEFsdY8VrpCxcu9Gly1HVtwoJ9ZGRkmG9p9Bsb2Id2n9F/TL0/g+np6WZ0KD6D9rR9+3aTY8FnMbI0114fSrULxpdffmk+a970/33x8fE+nz3tRqO5anz2rF9/geg35IrPnvUUFhZKTk6OrT53dIU6RjrUrDZRnX766dK1a1eZPHmySbIZMWJExdYQKtSdd95pxtbX7k86VJsOF6ytT1dddRV32oJBn/c3aJqwrf8D1CRETVjTvsMPP/ywnHjiieZ/ng8++KDpM6zjtsPa9aeL5jfpOOwaIGpwf/fdd5tv6nTIYES2+8zbb78tH3/8sck7c/ff1sERdL4YfdVuo/r/QK1HHW//73//u3m4OfPMM6k6i9efftZ0/8CBA818CJpjocOYnnPOOaY7IiJn9OjRpru2/v/t8OHDpp60a+jcuXPt9bmL9LBUdvbcc885mzdv7kxISDDDz3733XeRLhJKccUVVzgbNWpk6qxJkyZmfdOmTdw3C/rqq6/MUHr+iw5T6h5y9sEHH3Q2aNDADDPbq1cv54YNGyJdbIRQf5mZmc6+ffs6jzvuODOEYosWLZw33HCDc9euXdy/CAtUZ7pMnTrVc0xWVpbz1ltvNUNhpqSkOC+66CLnzp07I1puhFZ/27Ztc55zzjnOOnXqmH83W7du7bzrrrucaWlp3MII+9vf/mb+LdTnE/23Uf+fNm/ePNt97hz6n0gHNwAAAADsjRwLAAAAAOVGYAEAAACg3AgsAAAAAJQbgQUAAACAciOwAAAAAFBuBBYAAAAAyo3AAgAAAEC5EVgAAAAAKDcCCwBAVHE4HDJr1qxIFwMAqhwCCwBAhRk+fLh5sPdf+vfvz10GgCgXF+kCAACiiwYRU6dO9dmWmJgYsfIAAMKDFgsAQIXSIKJhw4Y+S+3atc0+bb146aWXZMCAAZKcnCzHH3+8fPDBBz7v//nnn+X88883++vWrSs33nijZGRk+Bzz+uuvS7t27cy1GjVqJCNHjvTZv2/fPrnoooskJSVFTjzxRPnkk0+oZQCoZAQWAICwevDBB+WSSy6Rn376Sa655hq58sorZd26dWbfkSNHpF+/fiYQ+eGHH+T999+XBQsW+AQOGpjcdtttJuDQIESDhtatW/tcY9y4cXL55ZfLmjVrZODAgeY6Bw4coKYBoBI5nE6nszIvAACoWjkW//3vfyUpKcln+3333WcWbbG4+eabTXDgduaZZ0rnzp3lxRdflFdeeUXuuece+eOPP6RatWpm/+zZs2XQoEGyY8cOadCggTRp0kRGjBghDz/8cMAy6DUeeOABmTBhgidYqV69unzxxRfkegBAJSLHAgBQoc477zyfwEHVqVPH83P37t199un66tWrzc/actGxY0dPUKF69OghhYWFsmHDBhM0aIDRq1evEsvQoUMHz896rtTUVNmzZ0+5fzcAQHAEFgCACqUP8v5dkyqK5l2EIj4+3mddAxINTgAAlYccCwBAWH333XfF1tu2bWt+1lfNvdDuS27ffvutxMTESJs2baRGjRrSsmVLWbhwIbUGABZDiwUAoELl5OTIrl27fP9nExcn9erVMz9rQvbpp58uZ599trz11luyfPlyee2118w+TbIeO3asDBs2TB566CHZu3ev/P3vf5drr73W5Fco3a55GvXr1zejSx0+fNgEH3ocACByCCwAABVqzpw5ZghYb9rasH79es+ITTNmzJBbb73VHPfOO+/IKaecYvbp8LBz586V22+/Xc444wyzriNITZo0yXMuDTqys7Pl6aefljvvvNMELJdeeim1CAARxqhQAIDw/U/H4ZCZM2fKkCFDuOsAEGXIsQAAAABQbgQWAAAAAMqNHAsAQNgwJysARC9aLAAAAACUG4EFAAAAgHIjsAAAAABQbgQWAAAAAMqNwAIAAABAuRFYAAAAACg3AgsAAAAA5UZgAQAAAKDcCCwAAAAASHn9Py2E4glM+CLsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"train_loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87d375b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 66])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=20000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=3\n",
      "구매번호:\n",
      "[1,2,3,4,5,6]\n",
      "[9,14,15,23,24,43]\n",
      "[1,4,19,21,23,27]\n",
      "[15,26,33,36,37,45]\n",
      "[1,2,28,31,32,36]\n",
      "[9,13,21,22,29,45]\n",
      "[18,21,30,31,38,45]\n",
      "[14,15,17,39,40,43]\n",
      "[7,8,10,25,36,43]\n",
      "[11,12,13,14,24,38]\n",
      "[2,4,25,30,38,45]\n",
      "[2,5,20,28,32,42]\n",
      "[2,5,7,12,19,31]\n",
      "[4,13,21,27,32,39]\n",
      "[24,26,30,38,44,45]\n",
      "[15,22,24,26,37,45]\n",
      "[4,9,12,14,18,25]\n",
      "[9,17,24,27,29,33]\n",
      "[13,20,29,39,43,44]\n",
      "[16,24,26,39,41,44]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 0\n",
      "수익률=0.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=20000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    "    \"티켓수=3\\n\"\n",
    "    \"구매번호:\\n\"\n",
    "    \"[1,2,3,4,5,6]\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "219f7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "checkpoint loaded from: lotto_gpt_best.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "# 체크포인트 로드 (파일 이름 맞게 수정 가능)\n",
    "ckpt_path = \"lotto_gpt_best.pt\"   # 또는 \"lotto_gpt_epoch030.pt\" 등\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "print(\"checkpoint loaded from:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt len (tokens): torch.Size([1, 25])\n",
      "model max_len: 512\n",
      "=== SAMPLE GENERATION ===\n",
      "money=1000\n",
      "winning=1,2,3,4,5,6\n",
      "bonus=7\n",
      "###\n",
      "티켓수=1\n",
      "구매번호:\n",
      "[13,14,18,32,36,37]\n",
      "3개일치 (5000원) = 0\n",
      "4개일치 (50000원) = 0\n",
      "5개일치 (1500000원) = 0\n",
      "5개보너스일치 (30000000원) = 0\n",
      "6개일치 (2000000000원) = 1\n",
      "수익률=200000000.0%\n"
     ]
    }
   ],
   "source": [
    "example_prompt = (\n",
    "    \"money=1000\\n\"\n",
    "    \"winning=1,2,3,4,5,6\\n\"\n",
    "    \"bonus=7\\n\"\n",
    "    \"###\\n\"\n",
    ")\n",
    "\n",
    "print(\"prompt len (tokens):\", tokenizer(example_prompt, return_tensors=\"pt\")[\"input_ids\"].shape)\n",
    "print(\"model max_len:\", model.config.max_len)\n",
    "\n",
    "generated = generate_text(model, tokenizer, example_prompt, max_new_tokens=512, device=device)\n",
    "print(\"=== SAMPLE GENERATION ===\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
